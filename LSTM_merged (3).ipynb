{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NqQ3LEM4zV1I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "sns.set(color_codes=True)\n",
        "import tensorflow as tf\n",
        "import matplotlib.dates as md\n",
        "\n",
        "from matplotlib import rc\n",
        "from numpy.random import seed\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "from pandas.plotting import autocorrelation_plot as auto_corr\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from matplotlib.dates import DateFormatter\n",
        "\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore') \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Dropout, Dense, TimeDistributed, RepeatVector\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "ek0hHAYT4bWO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.python.distribute import distribution_strategy_context as ds_context\n",
        "from tensorflow.python.eager import context\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.framework import tensor_shape\n",
        "from tensorflow.python.keras import activations\n",
        "from tensorflow.python.keras import backend\n",
        "from tensorflow.python.keras import constraints\n",
        "from tensorflow.python.keras import initializers\n",
        "from tensorflow.python.keras import regularizers\n",
        "from tensorflow.python.keras.engine.base_layer import Layer\n",
        "from tensorflow.python.keras.engine.input_spec import InputSpec\n",
        "from tensorflow.python.keras.saving.saved_model import layer_serialization\n",
        "from tensorflow.python.keras.utils import control_flow_util\n",
        "from tensorflow.python.keras.utils import generic_utils\n",
        "from tensorflow.python.keras.utils import tf_utils\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import control_flow_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import state_ops\n",
        "from tensorflow.python.platform import tf_logging as logging\n",
        "# from tensorflow.python.trackable import base as trackable\n",
        "from tensorflow.python.util import nest\n",
        "from tensorflow.python.util.tf_export import keras_export\n",
        "from tensorflow.tools.docs import doc_controls\n",
        "\n",
        "\n",
        "\n",
        "@keras_export('keras.layers.StackedRNNCells')\n",
        "class StackedRNNCells(Layer):\n",
        "  def __init__(self, cells, **kwargs):\n",
        "    for cell in cells:\n",
        "      if not 'call' in dir(cell):\n",
        "        raise ValueError('All cells must have a `call` method. '\n",
        "                         'received cells:', cells)\n",
        "      if not 'state_size' in dir(cell):\n",
        "        raise ValueError('All cells must have a '\n",
        "                         '`state_size` attribute. '\n",
        "                         'received cells:', cells)\n",
        "    self.cells = cells\n",
        "    self.reverse_state_order = kwargs.pop('reverse_state_order', False)\n",
        "    if self.reverse_state_order:\n",
        "      logging.warning('reverse_state_order=True warning')\n",
        "    super(StackedRNNCells, self).__init__(**kwargs)\n",
        "\n",
        "  @property\n",
        "  def state_size(self):\n",
        "    return tuple(c.state_size for c in\n",
        "                 (self.cells[::-1] if self.reverse_state_order else self.cells))\n",
        "\n",
        "  @property\n",
        "  def output_size(self):\n",
        "    if getattr(self.cells[-1], 'output_size', None) is not None:\n",
        "      return self.cells[-1].output_size\n",
        "    elif _is_multiple_state(self.cells[-1].state_size):\n",
        "      return self.cells[-1].state_size[0]\n",
        "    else:\n",
        "      return self.cells[-1].state_size\n",
        "\n",
        "  def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
        "    initial_states = []\n",
        "    for cell in self.cells[::-1] if self.reverse_state_order else self.cells:\n",
        "      get_initial_state_fn = getattr(cell, 'get_initial_state', None)\n",
        "      if get_initial_state_fn:\n",
        "        initial_states.append(get_initial_state_fn(\n",
        "            inputs=inputs, batch_size=batch_size, dtype=dtype))\n",
        "      else:\n",
        "        initial_states.append(_generate_zero_filled_state_for_cell(\n",
        "            cell, inputs, batch_size, dtype))\n",
        "\n",
        "    return tuple(initial_states)\n",
        "\n",
        "  def call(self, inputs, states, constants=None, training=None, **kwargs):\n",
        "    # Recover per-cell states.\n",
        "    state_size = (self.state_size[::-1]\n",
        "                  if self.reverse_state_order else self.state_size)\n",
        "    nested_states = nest.pack_sequence_as(state_size, nest.flatten(states))\n",
        "\n",
        "    new_nested_states = []\n",
        "    for cell, states in zip(self.cells, nested_states):\n",
        "      states = states if nest.is_nested(states) else [states]\n",
        "      is_tf_rnn_cell = getattr(cell, '_is_tf_rnn_cell', None) is not None\n",
        "      states = states[0] if len(states) == 1 and is_tf_rnn_cell else states\n",
        "      if generic_utils.has_arg(cell.call, 'training'):\n",
        "        kwargs['training'] = training\n",
        "      else:\n",
        "        kwargs.pop('training', None)\n",
        "      cell_call_fn = cell.__call__ if callable(cell) else cell.call\n",
        "      if generic_utils.has_arg(cell.call, 'constants'):\n",
        "        inputs, states = cell_call_fn(inputs, states,\n",
        "                                      constants=constants, **kwargs)\n",
        "      else:\n",
        "        inputs, states = cell_call_fn(inputs, states, **kwargs)\n",
        "      new_nested_states.append(states)\n",
        "\n",
        "    return inputs, nest.pack_sequence_as(state_size,\n",
        "                                         nest.flatten(new_nested_states))\n",
        "\n",
        "  @tf_utils.shape_type_conversion\n",
        "  def build(self, input_shape):\n",
        "    if isinstance(input_shape, list):\n",
        "      input_shape = input_shape[0]\n",
        "    for cell in self.cells:\n",
        "      if isinstance(cell, Layer) and not cell.built:\n",
        "        with backend.name_scope(cell.name):\n",
        "          cell.build(input_shape)\n",
        "          cell.built = True\n",
        "      if getattr(cell, 'output_size', None) is not None:\n",
        "        output_dim = cell.output_size\n",
        "      elif _is_multiple_state(cell.state_size):\n",
        "        output_dim = cell.state_size[0]\n",
        "      else:\n",
        "        output_dim = cell.state_size\n",
        "      input_shape = tuple([input_shape[0]] +\n",
        "                          tensor_shape.TensorShape(output_dim).as_list())\n",
        "    self.built = True\n",
        "\n",
        "  def get_config(self):\n",
        "    cells = []\n",
        "    for cell in self.cells:\n",
        "      cells.append(generic_utils.serialize_keras_object(cell))\n",
        "    config = {'cells': cells}\n",
        "    base_config = super(StackedRNNCells, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config, custom_objects=None):\n",
        "    from tensorflow.python.keras.layers import deserialize as deserialize_layer  # pylint: disable=g-import-not-at-top\n",
        "    cells = []\n",
        "    for cell_config in config.pop('cells'):\n",
        "      cells.append(\n",
        "          deserialize_layer(cell_config, custom_objects=custom_objects))\n",
        "    return cls(cells, **config)\n",
        "\n",
        "\n",
        "@keras_export('keras.layers.RNN')\n",
        "class RNN(Layer):\n",
        "  def __init__(self,\n",
        "               cell,\n",
        "               return_sequences=False,\n",
        "               return_state=False,\n",
        "               go_backwards=False,\n",
        "               stateful=False,\n",
        "               unroll=False,\n",
        "               time_major=False,\n",
        "               **kwargs):\n",
        "    if isinstance(cell, (list, tuple)):\n",
        "      cell = StackedRNNCells(cell)\n",
        "    if not 'call' in dir(cell):\n",
        "      raise ValueError('`cell` should have a `call` method. '\n",
        "                       'The RNN was passed:', cell)\n",
        "    if not 'state_size' in dir(cell):\n",
        "      raise ValueError('No Size Defined')\n",
        "    self.zero_output_for_mask = kwargs.pop('zero_output_for_mask', False)\n",
        "\n",
        "    if 'input_shape' not in kwargs and (\n",
        "        'input_dim' in kwargs or 'input_length' in kwargs):\n",
        "      input_shape = (kwargs.pop('input_length', None),\n",
        "                     kwargs.pop('input_dim', None))\n",
        "      kwargs['input_shape'] = input_shape\n",
        "\n",
        "    super(RNN, self).__init__(**kwargs)\n",
        "    self.cell = cell\n",
        "    self.return_sequences = return_sequences\n",
        "    self.return_state = return_state\n",
        "    self.go_backwards = go_backwards\n",
        "    self.stateful = stateful\n",
        "    self.unroll = unroll\n",
        "    self.time_major = time_major\n",
        "\n",
        "    self.supports_masking = True\n",
        "    self.input_spec = None\n",
        "    self.state_spec = None\n",
        "    self._states = None\n",
        "    self.constants_spec = None\n",
        "    self._num_constants = 0\n",
        "\n",
        "    if stateful:\n",
        "      if ds_context.has_strategy():\n",
        "        raise ValueError('RNNs with stateful=True not yet supported with '\n",
        "                         'tf.distribute.Strategy.')\n",
        "\n",
        "  @property\n",
        "  def _use_input_spec_as_call_signature(self):\n",
        "    if self.unroll:\n",
        "      return False\n",
        "    return super(RNN, self)._use_input_spec_as_call_signature\n",
        "\n",
        "  @property\n",
        "  def states(self):\n",
        "    if self._states is None:\n",
        "      state = nest.map_structure(lambda _: None, self.cell.state_size)\n",
        "      return state if nest.is_nested(self.cell.state_size) else [state]\n",
        "    return self._states\n",
        "\n",
        "  @states.setter\n",
        "  def states(self, states):\n",
        "    self._states = states\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    if isinstance(input_shape, list):\n",
        "      input_shape = input_shape[0]\n",
        "    try:\n",
        "      input_shape = tensor_shape.TensorShape(input_shape)\n",
        "    except (ValueError, TypeError):\n",
        "      input_shape = nest.flatten(input_shape)[0]\n",
        "\n",
        "    batch = input_shape[0]\n",
        "    time_step = input_shape[1]\n",
        "    if self.time_major:\n",
        "      batch, time_step = time_step, batch\n",
        "\n",
        "    if _is_multiple_state(self.cell.state_size):\n",
        "      state_size = self.cell.state_size\n",
        "    else:\n",
        "      state_size = [self.cell.state_size]\n",
        "\n",
        "    def _get_output_shape(flat_output_size):\n",
        "      output_dim = tensor_shape.TensorShape(flat_output_size).as_list()\n",
        "      if self.return_sequences:\n",
        "        if self.time_major:\n",
        "          output_shape = tensor_shape.TensorShape(\n",
        "              [time_step, batch] + output_dim)\n",
        "        else:\n",
        "          output_shape = tensor_shape.TensorShape(\n",
        "              [batch, time_step] + output_dim)\n",
        "      else:\n",
        "        output_shape = tensor_shape.TensorShape([batch] + output_dim)\n",
        "      return output_shape\n",
        "\n",
        "    if getattr(self.cell, 'output_size', None) is not None:\n",
        "      # cell.output_size could be nested structure.\n",
        "      output_shape = nest.flatten(nest.map_structure(\n",
        "          _get_output_shape, self.cell.output_size))\n",
        "      output_shape = output_shape[0] if len(output_shape) == 1 else output_shape\n",
        "    else:\n",
        "      output_shape = _get_output_shape(state_size[0])\n",
        "\n",
        "    if self.return_state:\n",
        "      def _get_state_shape(flat_state):\n",
        "        state_shape = [batch] + tensor_shape.TensorShape(flat_state).as_list()\n",
        "        return tensor_shape.TensorShape(state_shape)\n",
        "      state_shape = nest.map_structure(_get_state_shape, state_size)\n",
        "      return generic_utils.to_list(output_shape) + nest.flatten(state_shape)\n",
        "    else:\n",
        "      return output_shape\n",
        "\n",
        "  def compute_mask(self, inputs, mask):\n",
        "    mask = nest.flatten(mask)[0]\n",
        "    output_mask = mask if self.return_sequences else None\n",
        "    if self.return_state:\n",
        "      state_mask = [None for _ in self.states]\n",
        "      return [output_mask] + state_mask\n",
        "    else:\n",
        "      return output_mask\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    if isinstance(input_shape, list):\n",
        "      input_shape = input_shape[0]\n",
        "\n",
        "    def get_input_spec(shape):\n",
        "      if isinstance(shape, tensor_shape.TensorShape):\n",
        "        input_spec_shape = shape.as_list()\n",
        "      else:\n",
        "        input_spec_shape = list(shape)\n",
        "      batch_index, time_step_index = (1, 0) if self.time_major else (0, 1)\n",
        "      if not self.stateful:\n",
        "        input_spec_shape[batch_index] = None\n",
        "      input_spec_shape[time_step_index] = None\n",
        "      return InputSpec(shape=tuple(input_spec_shape))\n",
        "\n",
        "    def get_step_input_shape(shape):\n",
        "      if isinstance(shape, tensor_shape.TensorShape):\n",
        "        shape = tuple(shape.as_list())\n",
        "      return shape[1:] if self.time_major else (shape[0],) + shape[2:]\n",
        "\n",
        "    try:\n",
        "      input_shape = tensor_shape.TensorShape(input_shape)\n",
        "    except (ValueError, TypeError):\n",
        "      pass\n",
        "\n",
        "    if not nest.is_nested(input_shape):\n",
        "      if self.input_spec is not None:\n",
        "        self.input_spec[0] = get_input_spec(input_shape)\n",
        "      else:\n",
        "        self.input_spec = [get_input_spec(input_shape)]\n",
        "      step_input_shape = get_step_input_shape(input_shape)\n",
        "    else:\n",
        "      if self.input_spec is not None:\n",
        "        self.input_spec[0] = nest.map_structure(get_input_spec, input_shape)\n",
        "      else:\n",
        "        self.input_spec = generic_utils.to_list(\n",
        "            nest.map_structure(get_input_spec, input_shape))\n",
        "      step_input_shape = nest.map_structure(get_step_input_shape, input_shape)\n",
        "\n",
        "    # allow cell (if layer) to build before we set or validate state_spec.\n",
        "    if isinstance(self.cell, Layer) and not self.cell.built:\n",
        "      with backend.name_scope(self.cell.name):\n",
        "        self.cell.build(step_input_shape)\n",
        "        self.cell.built = True\n",
        "\n",
        "    # set or validate state_spec\n",
        "    if _is_multiple_state(self.cell.state_size):\n",
        "      state_size = list(self.cell.state_size)\n",
        "    else:\n",
        "      state_size = [self.cell.state_size]\n",
        "\n",
        "    if self.state_spec is not None:\n",
        "      self._validate_state_spec(state_size, self.state_spec)\n",
        "    else:\n",
        "      self.state_spec = [\n",
        "          InputSpec(shape=[None] + tensor_shape.TensorShape(dim).as_list())\n",
        "          for dim in state_size\n",
        "      ]\n",
        "    if self.stateful:\n",
        "      self.reset_states()\n",
        "    self.built = True\n",
        "\n",
        "  @staticmethod\n",
        "  def _validate_state_spec(cell_state_sizes, init_state_specs):\n",
        "\n",
        "    validation_error = ValueError(\n",
        "        ' error '.format(init_state_specs, cell_state_sizes))\n",
        "    flat_cell_state_sizes = nest.flatten(cell_state_sizes)\n",
        "    flat_state_specs = nest.flatten(init_state_specs)\n",
        "\n",
        "    if len(flat_cell_state_sizes) != len(flat_state_specs):\n",
        "      raise validation_error\n",
        "    for cell_state_spec, cell_state_size in zip(flat_state_specs,\n",
        "                                                flat_cell_state_sizes):\n",
        "      if not tensor_shape.TensorShape(\n",
        "          # Ignore the first axis for init_state which is for batch\n",
        "          cell_state_spec.shape[1:]).is_compatible_with(\n",
        "              tensor_shape.TensorShape(cell_state_size)):\n",
        "        raise validation_error\n",
        "\n",
        "  @doc_controls.do_not_doc_inheritable\n",
        "  def get_initial_state(self, inputs):\n",
        "    get_initial_state_fn = getattr(self.cell, 'get_initial_state', None)\n",
        "\n",
        "    if nest.is_nested(inputs):\n",
        "      inputs = nest.flatten(inputs)[0]\n",
        "\n",
        "    input_shape = array_ops.shape(inputs)\n",
        "    batch_size = input_shape[1] if self.time_major else input_shape[0]\n",
        "    dtype = inputs.dtype\n",
        "    if get_initial_state_fn:\n",
        "      init_state = get_initial_state_fn(\n",
        "          inputs=None, batch_size=batch_size, dtype=dtype)\n",
        "    else:\n",
        "      init_state = _generate_zero_filled_state(batch_size, self.cell.state_size,\n",
        "                                               dtype)\n",
        "    if not nest.is_nested(init_state):\n",
        "      init_state = [init_state]\n",
        "    return list(init_state)\n",
        "\n",
        "  def __call__(self, inputs, initial_state=None, constants=None, **kwargs):\n",
        "    inputs, initial_state, constants = _standardize_args(inputs,\n",
        "                                                         initial_state,\n",
        "                                                         constants,\n",
        "                                                         self._num_constants)\n",
        "\n",
        "    if initial_state is None and constants is None:\n",
        "      return super(RNN, self).__call__(inputs, **kwargs)\n",
        "\n",
        "    additional_inputs = []\n",
        "    additional_specs = []\n",
        "    if initial_state is not None:\n",
        "      additional_inputs += initial_state\n",
        "      self.state_spec = nest.map_structure(\n",
        "          lambda s: InputSpec(shape=backend.int_shape(s)), initial_state)\n",
        "      additional_specs += self.state_spec\n",
        "    if constants is not None:\n",
        "      additional_inputs += constants\n",
        "      self.constants_spec = [\n",
        "          InputSpec(shape=backend.int_shape(constant)) for constant in constants\n",
        "      ]\n",
        "      self._num_constants = len(constants)\n",
        "      additional_specs += self.constants_spec\n",
        "    flat_additional_inputs = nest.flatten(additional_inputs)\n",
        "    is_keras_tensor = backend.is_keras_tensor(\n",
        "        flat_additional_inputs[0]) if flat_additional_inputs else True\n",
        "    for tensor in flat_additional_inputs:\n",
        "      if backend.is_keras_tensor(tensor) != is_keras_tensor:\n",
        "        raise ValueError(' error ')\n",
        "\n",
        "    if is_keras_tensor:\n",
        "      full_input = [inputs] + additional_inputs\n",
        "      if self.built:\n",
        "        full_input_spec = self.input_spec + additional_specs\n",
        "      else:\n",
        "        full_input_spec = generic_utils.to_list(\n",
        "            nest.map_structure(lambda _: None, inputs)) + additional_specs\n",
        "      self.input_spec = full_input_spec\n",
        "      output = super(RNN, self).__call__(full_input, **kwargs)\n",
        "      self.input_spec = self.input_spec[:-len(additional_specs)]\n",
        "      return output\n",
        "    else:\n",
        "      if initial_state is not None:\n",
        "        kwargs['initial_state'] = initial_state\n",
        "      if constants is not None:\n",
        "        kwargs['constants'] = constants\n",
        "      return super(RNN, self).__call__(inputs, **kwargs)\n",
        "\n",
        "  def call(self,\n",
        "           inputs,\n",
        "           mask=None,\n",
        "           training=None,\n",
        "           initial_state=None,\n",
        "           constants=None):\n",
        "    inputs, row_lengths = backend.convert_inputs_if_ragged(inputs)\n",
        "    is_ragged_input = (row_lengths is not None)\n",
        "    self._validate_args_if_ragged(is_ragged_input, mask)\n",
        "\n",
        "    inputs, initial_state, constants = self._process_inputs(\n",
        "        inputs, initial_state, constants)\n",
        "\n",
        "    self._maybe_reset_cell_dropout_mask(self.cell)\n",
        "    if isinstance(self.cell, StackedRNNCells):\n",
        "      for cell in self.cell.cells:\n",
        "        self._maybe_reset_cell_dropout_mask(cell)\n",
        "\n",
        "    if mask is not None:\n",
        "      mask = nest.flatten(mask)[0]\n",
        "\n",
        "    if nest.is_nested(inputs):\n",
        "      input_shape = backend.int_shape(nest.flatten(inputs)[0])\n",
        "    else:\n",
        "      input_shape = backend.int_shape(inputs)\n",
        "    timesteps = input_shape[0] if self.time_major else input_shape[1]\n",
        "    if self.unroll and timesteps is None:\n",
        "      raise ValueError('Cannot unroll a RNN if the time dimension is undefined.')\n",
        "\n",
        "    kwargs = {}\n",
        "    if generic_utils.has_arg(self.cell.call, 'training'):\n",
        "      kwargs['training'] = training\n",
        "\n",
        "    is_tf_rnn_cell = getattr(self.cell, '_is_tf_rnn_cell', None) is not None\n",
        "    cell_call_fn = self.cell.__call__ if callable(self.cell) else self.cell.call\n",
        "    if constants:\n",
        "      if not generic_utils.has_arg(self.cell.call, 'constants'):\n",
        "        raise ValueError('RNN cell does not support constants')\n",
        "\n",
        "      def step(inputs, states):\n",
        "        constants = states[-self._num_constants:]  # pylint: disable=invalid-unary-operand-type\n",
        "        states = states[:-self._num_constants]  # pylint: disable=invalid-unary-operand-type\n",
        "\n",
        "        states = states[0] if len(states) == 1 and is_tf_rnn_cell else states\n",
        "        output, new_states = cell_call_fn(\n",
        "            inputs, states, constants=constants, **kwargs)\n",
        "        if not nest.is_nested(new_states):\n",
        "          new_states = [new_states]\n",
        "        return output, new_states\n",
        "    else:\n",
        "\n",
        "      def step(inputs, states):\n",
        "        states = states[0] if len(states) == 1 and is_tf_rnn_cell else states\n",
        "        output, new_states = cell_call_fn(inputs, states, **kwargs)\n",
        "        if not nest.is_nested(new_states):\n",
        "          new_states = [new_states]\n",
        "        return output, new_states\n",
        "    last_output, outputs, states = backend.rnn(\n",
        "        step,\n",
        "        inputs,\n",
        "        initial_state,\n",
        "        constants=constants,\n",
        "        go_backwards=self.go_backwards,\n",
        "        mask=mask,\n",
        "        unroll=self.unroll,\n",
        "        input_length=row_lengths if row_lengths is not None else timesteps,\n",
        "        time_major=self.time_major,\n",
        "        zero_output_for_mask=self.zero_output_for_mask)\n",
        "\n",
        "    if self.stateful:\n",
        "      updates = [\n",
        "          state_ops.assign(self_state, state) for self_state, state in zip(\n",
        "              nest.flatten(self.states), nest.flatten(states))\n",
        "      ]\n",
        "      self.add_update(updates)\n",
        "\n",
        "    if self.return_sequences:\n",
        "      output = backend.maybe_convert_to_ragged(\n",
        "          is_ragged_input, outputs, row_lengths, go_backwards=self.go_backwards)\n",
        "    else:\n",
        "      output = last_output\n",
        "\n",
        "    if self.return_state:\n",
        "      if not isinstance(states, (list, tuple)):\n",
        "        states = [states]\n",
        "      else:\n",
        "        states = list(states)\n",
        "      return generic_utils.to_list(output) + states\n",
        "    else:\n",
        "      return output\n",
        "\n",
        "  def _process_inputs(self, inputs, initial_state, constants):\n",
        "    if (isinstance(inputs, collections.abc.Sequence) and not isinstance(inputs, tuple)):\n",
        "      if not self._num_constants:\n",
        "        initial_state = inputs[1:]\n",
        "      else:\n",
        "        initial_state = inputs[1:-self._num_constants]\n",
        "        constants = inputs[-self._num_constants:]\n",
        "      if len(initial_state) == 0:\n",
        "        initial_state = None\n",
        "      inputs = inputs[0]\n",
        "\n",
        "    if self.stateful:\n",
        "      if initial_state is not None:\n",
        "        non_zero_count = math_ops.add_n([math_ops.count_nonzero_v2(s)\n",
        "                                         for s in nest.flatten(self.states)])\n",
        "        initial_state = control_flow_ops.cond(non_zero_count > 0,\n",
        "                                              true_fn=lambda: self.states,\n",
        "                                              false_fn=lambda: initial_state,\n",
        "                                              strict=True)\n",
        "      else:\n",
        "        initial_state = self.states\n",
        "    elif initial_state is None:\n",
        "      initial_state = self.get_initial_state(inputs)\n",
        "\n",
        "    if len(initial_state) != len(self.states):\n",
        "      raise ValueError('Layer has ' + str(len(self.states)) +\n",
        "                       ' states but was passed ' + str(len(initial_state)) +\n",
        "                       ' initial states.')\n",
        "    return inputs, initial_state, constants\n",
        "\n",
        "  def _validate_args_if_ragged(self, is_ragged_input, mask):\n",
        "    if not is_ragged_input:\n",
        "      return\n",
        "\n",
        "    if mask is not None:\n",
        "      raise ValueError('The mask passed in was '+str(mask)+' and cant be applied to RaggedTensor inputs layers')\n",
        "    if self.unroll:\n",
        "      raise ValueError('RaggedTensors unrolling not supported')\n",
        "\n",
        "  def _maybe_reset_cell_dropout_mask(self, cell):\n",
        "    if isinstance(cell, DropoutRNNCellMixin):\n",
        "      cell.reset_dropout_mask()\n",
        "      cell.reset_recurrent_dropout_mask()\n",
        "\n",
        "  def reset_states(self, states=None):\n",
        "\n",
        "    if not self.stateful:\n",
        "      raise AttributeError('Layer must be stateful.')\n",
        "    spec_shape = None\n",
        "    if self.input_spec is not None:\n",
        "      spec_shape = nest.flatten(self.input_spec[0])[0].shape\n",
        "    if spec_shape is None:\n",
        "      batch_size = None\n",
        "    else:\n",
        "      batch_size = spec_shape[1] if self.time_major else spec_shape[0]\n",
        "    if not batch_size:\n",
        "      raise ValueError('error')\n",
        "    # initialize state if None\n",
        "    if nest.flatten(self.states)[0] is None:\n",
        "      if getattr(self.cell, 'get_initial_state', None):\n",
        "        flat_init_state_values = nest.flatten(self.cell.get_initial_state(\n",
        "            inputs=None, batch_size=batch_size,\n",
        "            dtype=self.dtype or backend.floatx()))\n",
        "      else:\n",
        "        flat_init_state_values = nest.flatten(_generate_zero_filled_state(\n",
        "            batch_size, self.cell.state_size, self.dtype or backend.floatx()))\n",
        "      flat_states_variables = nest.map_structure(\n",
        "          backend.variable, flat_init_state_values)\n",
        "      self.states = nest.pack_sequence_as(self.cell.state_size,\n",
        "                                          flat_states_variables)\n",
        "      if not nest.is_nested(self.states):\n",
        "        self.states = [self.states]\n",
        "    elif states is None:\n",
        "      for state, size in zip(nest.flatten(self.states),\n",
        "                             nest.flatten(self.cell.state_size)):\n",
        "        backend.set_value(\n",
        "            state,\n",
        "            np.zeros([batch_size] + tensor_shape.TensorShape(size).as_list()))\n",
        "    else:\n",
        "      flat_states = nest.flatten(self.states)\n",
        "      flat_input_states = nest.flatten(states)\n",
        "      if len(flat_input_states) != len(flat_states):\n",
        "        raise ValueError('Layer ' + self.name + ' expects ' +\n",
        "                         str(len(flat_states)) + ' states, '\n",
        "                         'but it received ' + str(len(flat_input_states)) +\n",
        "                         ' state values. Input received: ' + str(states))\n",
        "      set_value_tuples = []\n",
        "      for i, (value, state) in enumerate(zip(flat_input_states,\n",
        "                                             flat_states)):\n",
        "        if value.shape != state.shape:\n",
        "          raise ValueError(\n",
        "              'State ' + str(i) + ' is incompatible with layer ' +\n",
        "              self.name + ': expected shape=' + str(\n",
        "                  (batch_size, state)) + ', found shape=' + str(value.shape))\n",
        "        set_value_tuples.append((state, value))\n",
        "      backend.batch_set_value(set_value_tuples)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        'return_sequences': self.return_sequences,\n",
        "        'return_state': self.return_state,\n",
        "        'go_backwards': self.go_backwards,\n",
        "        'stateful': self.stateful,\n",
        "        'unroll': self.unroll,\n",
        "        'time_major': self.time_major\n",
        "    }\n",
        "    if self._num_constants:\n",
        "      config['num_constants'] = self._num_constants\n",
        "    if self.zero_output_for_mask:\n",
        "      config['zero_output_for_mask'] = self.zero_output_for_mask\n",
        "\n",
        "    config['cell'] = generic_utils.serialize_keras_object(self.cell)\n",
        "    base_config = super(RNN, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config, custom_objects=None):\n",
        "    from tensorflow.python.keras.layers import deserialize as deserialize_layer  # pylint: disable=g-import-not-at-top\n",
        "    cell = deserialize_layer(config.pop('cell'), custom_objects=custom_objects)\n",
        "    num_constants = config.pop('num_constants', 0)\n",
        "    layer = cls(cell, **config)\n",
        "    layer._num_constants = num_constants\n",
        "    return layer\n",
        "\n",
        "  @property\n",
        "  def _trackable_saved_model_saver(self):\n",
        "    return layer_serialization.RNNSavedModelSaver(self)\n",
        "\n",
        "@doc_controls.do_not_generate_docs\n",
        "class DropoutRNNCellMixin(object):\n",
        "\n",
        "\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    self._create_non_trackable_mask_cache()\n",
        "    super(DropoutRNNCellMixin, self).__init__(*args, **kwargs)\n",
        "\n",
        "  def _create_non_trackable_mask_cache(self):\n",
        "\n",
        "    self._dropout_mask_cache = backend.ContextValueCache(\n",
        "        self._create_dropout_mask)\n",
        "    self._recurrent_dropout_mask_cache = backend.ContextValueCache(\n",
        "        self._create_recurrent_dropout_mask)\n",
        "\n",
        "  def reset_dropout_mask(self):\n",
        "\n",
        "    self._dropout_mask_cache.clear()\n",
        "\n",
        "  def reset_recurrent_dropout_mask(self):\n",
        "\n",
        "    self._recurrent_dropout_mask_cache.clear()\n",
        "\n",
        "  def _create_dropout_mask(self, inputs, training, count=1):\n",
        "    return _generate_dropout_mask(\n",
        "        array_ops.ones_like(inputs),\n",
        "        self.dropout,\n",
        "        training=training,\n",
        "        count=count)\n",
        "\n",
        "  def _create_recurrent_dropout_mask(self, inputs, training, count=1):\n",
        "    return _generate_dropout_mask(\n",
        "        array_ops.ones_like(inputs),\n",
        "        self.recurrent_dropout,\n",
        "        training=training,\n",
        "        count=count)\n",
        "\n",
        "  def get_dropout_mask_for_cell(self, inputs, training, count=1):\n",
        "\n",
        "    if self.dropout == 0:\n",
        "      return None\n",
        "    init_kwargs = dict(inputs=inputs, training=training, count=count)\n",
        "    return self._dropout_mask_cache.setdefault(kwargs=init_kwargs)\n",
        "\n",
        "  def get_recurrent_dropout_mask_for_cell(self, inputs, training, count=1):\n",
        "\n",
        "    if self.recurrent_dropout == 0:\n",
        "      return None\n",
        "    init_kwargs = dict(inputs=inputs, training=training, count=count)\n",
        "    return self._recurrent_dropout_mask_cache.setdefault(kwargs=init_kwargs)\n",
        "\n",
        "  def __getstate__(self):\n",
        "    state = super(DropoutRNNCellMixin, self).__getstate__()\n",
        "    state.pop('_dropout_mask_cache', None)\n",
        "    state.pop('_recurrent_dropout_mask_cache', None)\n",
        "    return state\n",
        "\n",
        "  def __setstate__(self, state):\n",
        "    state['_dropout_mask_cache'] = backend.ContextValueCache(\n",
        "        self._create_dropout_mask)\n",
        "    state['_recurrent_dropout_mask_cache'] = backend.ContextValueCache(\n",
        "        self._create_recurrent_dropout_mask)\n",
        "    super(DropoutRNNCellMixin, self).__setstate__(state)\n",
        "\n",
        "\n",
        "@keras_export('keras.layers.SimpleRNNCell')\n",
        "class SimpleRNNCell(DropoutRNNCellMixin, Layer):\n",
        "\n",
        "  def __init__(self,\n",
        "               units,\n",
        "               activation='tanh',\n",
        "               use_bias=True,\n",
        "               kernel_initializer='glorot_uniform',\n",
        "               recurrent_initializer='orthogonal',\n",
        "               bias_initializer='zeros',\n",
        "               kernel_regularizer=None,\n",
        "               recurrent_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               recurrent_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               dropout=0.,\n",
        "               recurrent_dropout=0.,\n",
        "               **kwargs):\n",
        "    if units < 0:\n",
        "      raise ValueError(f'error')\n",
        "    # By default use cached variable under v2 mode, see b/143699808.\n",
        "    if ops.executing_eagerly_outside_functions():\n",
        "      self._enable_caching_device = kwargs.pop('enable_caching_device', True)\n",
        "    else:\n",
        "      self._enable_caching_device = kwargs.pop('enable_caching_device', False)\n",
        "    super(SimpleRNNCell, self).__init__(**kwargs)\n",
        "    self.units = units\n",
        "    self.activation = activations.get(activation)\n",
        "    self.use_bias = use_bias\n",
        "\n",
        "    self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "    self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
        "    self.bias_initializer = initializers.get(bias_initializer)\n",
        "\n",
        "    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "    self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n",
        "    self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "\n",
        "    self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "    self.recurrent_constraint = constraints.get(recurrent_constraint)\n",
        "    self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "    self.dropout = min(1., max(0., dropout))\n",
        "    self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n",
        "    self.state_size = self.units\n",
        "    self.output_size = self.units\n",
        "\n",
        "  @tf_utils.shape_type_conversion\n",
        "  def build(self, input_shape):\n",
        "    default_caching_device = _caching_device(self)\n",
        "    self.kernel = self.add_weight(\n",
        "        shape=(input_shape[-1], self.units),\n",
        "        name='kernel',\n",
        "        initializer=self.kernel_initializer,\n",
        "        regularizer=self.kernel_regularizer,\n",
        "        constraint=self.kernel_constraint,\n",
        "        caching_device=default_caching_device)\n",
        "    self.recurrent_kernel = self.add_weight(\n",
        "        shape=(self.units, self.units),\n",
        "        name='recurrent_kernel',\n",
        "        initializer=self.recurrent_initializer,\n",
        "        regularizer=self.recurrent_regularizer,\n",
        "        constraint=self.recurrent_constraint,\n",
        "        caching_device=default_caching_device)\n",
        "    if self.use_bias:\n",
        "      self.bias = self.add_weight(\n",
        "          shape=(self.units,),\n",
        "          name='bias',\n",
        "          initializer=self.bias_initializer,\n",
        "          regularizer=self.bias_regularizer,\n",
        "          constraint=self.bias_constraint,\n",
        "          caching_device=default_caching_device)\n",
        "    else:\n",
        "      self.bias = None\n",
        "    self.built = True\n",
        "\n",
        "  def call(self, inputs, states, training=None):\n",
        "    prev_output = states[0] if nest.is_nested(states) else states\n",
        "    dp_mask = self.get_dropout_mask_for_cell(inputs, training)\n",
        "    rec_dp_mask = self.get_recurrent_dropout_mask_for_cell(\n",
        "        prev_output, training)\n",
        "\n",
        "    if dp_mask is not None:\n",
        "      h = backend.dot(inputs * dp_mask, self.kernel)\n",
        "    else:\n",
        "      h = backend.dot(inputs, self.kernel)\n",
        "    if self.bias is not None:\n",
        "      h = backend.bias_add(h, self.bias)\n",
        "\n",
        "    if rec_dp_mask is not None:\n",
        "      prev_output = prev_output * rec_dp_mask\n",
        "    output = h + backend.dot(prev_output, self.recurrent_kernel)\n",
        "    if self.activation is not None:\n",
        "      output = self.activation(output)\n",
        "\n",
        "    new_state = [output] if nest.is_nested(states) else output\n",
        "    return output, new_state\n",
        "\n",
        "  def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
        "    return _generate_zero_filled_state_for_cell(self, inputs, batch_size, dtype)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        'units':\n",
        "            self.units,\n",
        "        'activation':\n",
        "            activations.serialize(self.activation),\n",
        "        'use_bias':\n",
        "            self.use_bias,\n",
        "        'kernel_initializer':\n",
        "            initializers.serialize(self.kernel_initializer),\n",
        "        'recurrent_initializer':\n",
        "            initializers.serialize(self.recurrent_initializer),\n",
        "        'bias_initializer':\n",
        "            initializers.serialize(self.bias_initializer),\n",
        "        'kernel_regularizer':\n",
        "            regularizers.serialize(self.kernel_regularizer),\n",
        "        'recurrent_regularizer':\n",
        "            regularizers.serialize(self.recurrent_regularizer),\n",
        "        'bias_regularizer':\n",
        "            regularizers.serialize(self.bias_regularizer),\n",
        "        'kernel_constraint':\n",
        "            constraints.serialize(self.kernel_constraint),\n",
        "        'recurrent_constraint':\n",
        "            constraints.serialize(self.recurrent_constraint),\n",
        "        'bias_constraint':\n",
        "            constraints.serialize(self.bias_constraint),\n",
        "        'dropout':\n",
        "            self.dropout,\n",
        "        'recurrent_dropout':\n",
        "            self.recurrent_dropout\n",
        "    }\n",
        "    config.update(_config_for_enable_caching_device(self))\n",
        "    base_config = super(SimpleRNNCell, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "\n",
        "@keras_export('keras.layers.SimpleRNN')\n",
        "class SimpleRNN(RNN):\n",
        "\n",
        "  def __init__(self,\n",
        "               units,\n",
        "               activation='tanh',\n",
        "               use_bias=True,\n",
        "               kernel_initializer='glorot_uniform',\n",
        "               recurrent_initializer='orthogonal',\n",
        "               bias_initializer='zeros',\n",
        "               kernel_regularizer=None,\n",
        "               recurrent_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               recurrent_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               dropout=0.,\n",
        "               recurrent_dropout=0.,\n",
        "               return_sequences=False,\n",
        "               return_state=False,\n",
        "               go_backwards=False,\n",
        "               stateful=False,\n",
        "               unroll=False,\n",
        "               **kwargs):\n",
        "    if 'implementation' in kwargs:\n",
        "      kwargs.pop('implementation')\n",
        "      logging.warning('warning')\n",
        "    if 'enable_caching_device' in kwargs:\n",
        "      cell_kwargs = {'enable_caching_device':\n",
        "                     kwargs.pop('enable_caching_device')}\n",
        "    else:\n",
        "      cell_kwargs = {}\n",
        "    cell = SimpleRNNCell(\n",
        "        units,\n",
        "        activation=activation,\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        recurrent_initializer=recurrent_initializer,\n",
        "        bias_initializer=bias_initializer,\n",
        "        kernel_regularizer=kernel_regularizer,\n",
        "        recurrent_regularizer=recurrent_regularizer,\n",
        "        bias_regularizer=bias_regularizer,\n",
        "        kernel_constraint=kernel_constraint,\n",
        "        recurrent_constraint=recurrent_constraint,\n",
        "        bias_constraint=bias_constraint,\n",
        "        dropout=dropout,\n",
        "        recurrent_dropout=recurrent_dropout,\n",
        "        dtype=kwargs.get('dtype'),\n",
        "        trainable=kwargs.get('trainable', True),\n",
        "        **cell_kwargs)\n",
        "    super(SimpleRNN, self).__init__(\n",
        "        cell,\n",
        "        return_sequences=return_sequences,\n",
        "        return_state=return_state,\n",
        "        go_backwards=go_backwards,\n",
        "        stateful=stateful,\n",
        "        unroll=unroll,\n",
        "        **kwargs)\n",
        "    self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "    self.input_spec = [InputSpec(ndim=3)]\n",
        "\n",
        "  def call(self, inputs, mask=None, training=None, initial_state=None):\n",
        "    return super(SimpleRNN, self).call(\n",
        "        inputs, mask=mask, training=training, initial_state=initial_state)\n",
        "\n",
        "  @property\n",
        "  def units(self):\n",
        "    return self.cell.units\n",
        "\n",
        "  @property\n",
        "  def activation(self):\n",
        "    return self.cell.activation\n",
        "\n",
        "  @property\n",
        "  def use_bias(self):\n",
        "    return self.cell.use_bias\n",
        "\n",
        "  @property\n",
        "  def kernel_initializer(self):\n",
        "    return self.cell.kernel_initializer\n",
        "\n",
        "  @property\n",
        "  def recurrent_initializer(self):\n",
        "    return self.cell.recurrent_initializer\n",
        "\n",
        "  @property\n",
        "  def bias_initializer(self):\n",
        "    return self.cell.bias_initializer\n",
        "\n",
        "  @property\n",
        "  def kernel_regularizer(self):\n",
        "    return self.cell.kernel_regularizer\n",
        "\n",
        "  @property\n",
        "  def recurrent_regularizer(self):\n",
        "    return self.cell.recurrent_regularizer\n",
        "\n",
        "  @property\n",
        "  def bias_regularizer(self):\n",
        "    return self.cell.bias_regularizer\n",
        "\n",
        "  @property\n",
        "  def kernel_constraint(self):\n",
        "    return self.cell.kernel_constraint\n",
        "\n",
        "  @property\n",
        "  def recurrent_constraint(self):\n",
        "    return self.cell.recurrent_constraint\n",
        "\n",
        "  @property\n",
        "  def bias_constraint(self):\n",
        "    return self.cell.bias_constraint\n",
        "\n",
        "  @property\n",
        "  def dropout(self):\n",
        "    return self.cell.dropout\n",
        "\n",
        "  @property\n",
        "  def recurrent_dropout(self):\n",
        "    return self.cell.recurrent_dropout\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        'units':\n",
        "            self.units,\n",
        "        'activation':\n",
        "            activations.serialize(self.activation),\n",
        "        'use_bias':\n",
        "            self.use_bias,\n",
        "        'kernel_initializer':\n",
        "            initializers.serialize(self.kernel_initializer),\n",
        "        'recurrent_initializer':\n",
        "            initializers.serialize(self.recurrent_initializer),\n",
        "        'bias_initializer':\n",
        "            initializers.serialize(self.bias_initializer),\n",
        "        'kernel_regularizer':\n",
        "            regularizers.serialize(self.kernel_regularizer),\n",
        "        'recurrent_regularizer':\n",
        "            regularizers.serialize(self.recurrent_regularizer),\n",
        "        'bias_regularizer':\n",
        "            regularizers.serialize(self.bias_regularizer),\n",
        "        'activity_regularizer':\n",
        "            regularizers.serialize(self.activity_regularizer),\n",
        "        'kernel_constraint':\n",
        "            constraints.serialize(self.kernel_constraint),\n",
        "        'recurrent_constraint':\n",
        "            constraints.serialize(self.recurrent_constraint),\n",
        "        'bias_constraint':\n",
        "            constraints.serialize(self.bias_constraint),\n",
        "        'dropout':\n",
        "            self.dropout,\n",
        "        'recurrent_dropout':\n",
        "            self.recurrent_dropout\n",
        "    }\n",
        "    base_config = super(SimpleRNN, self).get_config()\n",
        "    config.update(_config_for_enable_caching_device(self.cell))\n",
        "    del base_config['cell']\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    if 'implementation' in config:\n",
        "      config.pop('implementation')\n",
        "    return cls(**config)\n",
        "\n",
        "@keras_export(v1=['keras.layers.LSTMCell'])\n",
        "class LSTMCell(DropoutRNNCellMixin, Layer):\n",
        "\n",
        "  def __init__(self,\n",
        "               units,\n",
        "               activation='tanh',\n",
        "               recurrent_activation='hard_sigmoid',\n",
        "               use_bias=True,\n",
        "               kernel_initializer='glorot_uniform',\n",
        "               recurrent_initializer='orthogonal',\n",
        "               bias_initializer='zeros',\n",
        "               unit_forget_bias=True,\n",
        "               kernel_regularizer=None,\n",
        "               recurrent_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               recurrent_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               dropout=0.,\n",
        "               recurrent_dropout=0.,\n",
        "               **kwargs):\n",
        "    if units < 0:\n",
        "      raise ValueError(f'error')\n",
        "    # By default use cached variable under v2 mode, see b/143699808.\n",
        "    if ops.executing_eagerly_outside_functions():\n",
        "      self._enable_caching_device = kwargs.pop('enable_caching_device', True)\n",
        "    else:\n",
        "      self._enable_caching_device = kwargs.pop('enable_caching_device', False)\n",
        "    super(LSTMCell, self).__init__(**kwargs)\n",
        "    self.units = units\n",
        "    self.activation = activations.get(activation)\n",
        "    self.recurrent_activation = activations.get(recurrent_activation)\n",
        "    self.use_bias = use_bias\n",
        "\n",
        "    self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "    self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
        "    self.bias_initializer = initializers.get(bias_initializer)\n",
        "    self.unit_forget_bias = unit_forget_bias\n",
        "\n",
        "    self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "    self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\n",
        "    self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "\n",
        "    self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "    self.recurrent_constraint = constraints.get(recurrent_constraint)\n",
        "    self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "    self.dropout = min(1., max(0., dropout))\n",
        "    self.recurrent_dropout = min(1., max(0., recurrent_dropout))\n",
        "    implementation = kwargs.pop('implementation', 1)\n",
        "    if self.recurrent_dropout != 0 and implementation != 1:\n",
        "      self.implementation = 1\n",
        "    else:\n",
        "      self.implementation = implementation\n",
        "    self.state_size = [self.units, self.units]\n",
        "    self.output_size = self.units\n",
        "\n",
        "  @tf_utils.shape_type_conversion\n",
        "  def build(self, input_shape):\n",
        "    default_caching_device = _caching_device(self)\n",
        "    input_dim = input_shape[-1]\n",
        "    self.kernel = self.add_weight(\n",
        "        shape=(input_dim, self.units * 4),\n",
        "        name='kernel',\n",
        "        initializer=self.kernel_initializer,\n",
        "        regularizer=self.kernel_regularizer,\n",
        "        constraint=self.kernel_constraint,\n",
        "        caching_device=default_caching_device)\n",
        "    self.recurrent_kernel = self.add_weight(\n",
        "        shape=(self.units, self.units * 4),\n",
        "        name='recurrent_kernel',\n",
        "        initializer=self.recurrent_initializer,\n",
        "        regularizer=self.recurrent_regularizer,\n",
        "        constraint=self.recurrent_constraint,\n",
        "        caching_device=default_caching_device)\n",
        "\n",
        "    if self.use_bias:\n",
        "      if self.unit_forget_bias:\n",
        "\n",
        "        def bias_initializer(_, *args, **kwargs):\n",
        "          return backend.concatenate([\n",
        "              self.bias_initializer((self.units,), *args, **kwargs),\n",
        "              initializers.get('ones')((self.units,), *args, **kwargs),\n",
        "              self.bias_initializer((self.units * 2,), *args, **kwargs),\n",
        "          ])\n",
        "      else:\n",
        "        bias_initializer = self.bias_initializer\n",
        "      self.bias = self.add_weight(\n",
        "          shape=(self.units * 4,),\n",
        "          name='bias',\n",
        "          initializer=bias_initializer,\n",
        "          regularizer=self.bias_regularizer,\n",
        "          constraint=self.bias_constraint,\n",
        "          caching_device=default_caching_device)\n",
        "    else:\n",
        "      self.bias = None\n",
        "    self.built = True\n",
        "\n",
        "  def _compute_carry_and_output(self, x, h_tm1, c_tm1):\n",
        "    x_i, x_f, x_c, x_o = x\n",
        "    h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o = h_tm1\n",
        "    i = self.recurrent_activation(\n",
        "        x_i + backend.dot(h_tm1_i, self.recurrent_kernel[:, :self.units]))\n",
        "    f = self.recurrent_activation(x_f + backend.dot(\n",
        "        h_tm1_f, self.recurrent_kernel[:, self.units:self.units * 2]))\n",
        "    c = f * c_tm1 + i * self.activation(x_c + backend.dot(\n",
        "        h_tm1_c, self.recurrent_kernel[:, self.units * 2:self.units * 3]))\n",
        "    o = self.recurrent_activation(\n",
        "        x_o + backend.dot(h_tm1_o, self.recurrent_kernel[:, self.units * 3:]))\n",
        "    return c, o\n",
        "\n",
        "  def _compute_carry_and_output_fused(self, z, c_tm1):\n",
        "    z0, z1, z2, z3 = z\n",
        "    i = self.recurrent_activation(z0)\n",
        "    f = self.recurrent_activation(z1)\n",
        "    c = f * c_tm1 + i * self.activation(z2)\n",
        "    o = self.recurrent_activation(z3)\n",
        "    return c, o\n",
        "\n",
        "  def call(self, inputs, states, training=None):\n",
        "    h_tm1 = states[0]  # previous memory state\n",
        "    c_tm1 = states[1]  # previous carry state\n",
        "\n",
        "    dp_mask = self.get_dropout_mask_for_cell(inputs, training, count=4)\n",
        "    rec_dp_mask = self.get_recurrent_dropout_mask_for_cell(\n",
        "        h_tm1, training, count=4)\n",
        "\n",
        "    if self.implementation == 1:\n",
        "      if 0 < self.dropout < 1.:\n",
        "        inputs_i = inputs * dp_mask[0]\n",
        "        inputs_f = inputs * dp_mask[1]\n",
        "        inputs_c = inputs * dp_mask[2]\n",
        "        inputs_o = inputs * dp_mask[3]\n",
        "      else:\n",
        "        inputs_i = inputs\n",
        "        inputs_f = inputs\n",
        "        inputs_c = inputs\n",
        "        inputs_o = inputs\n",
        "      k_i, k_f, k_c, k_o = array_ops.split(\n",
        "          self.kernel, num_or_size_splits=4, axis=1)\n",
        "      x_i = backend.dot(inputs_i, k_i)\n",
        "      x_f = backend.dot(inputs_f, k_f)\n",
        "      x_c = backend.dot(inputs_c, k_c)\n",
        "      x_o = backend.dot(inputs_o, k_o)\n",
        "      if self.use_bias:\n",
        "        b_i, b_f, b_c, b_o = array_ops.split(\n",
        "            self.bias, num_or_size_splits=4, axis=0)\n",
        "        x_i = backend.bias_add(x_i, b_i)\n",
        "        x_f = backend.bias_add(x_f, b_f)\n",
        "        x_c = backend.bias_add(x_c, b_c)\n",
        "        x_o = backend.bias_add(x_o, b_o)\n",
        "\n",
        "      if 0 < self.recurrent_dropout < 1.:\n",
        "        h_tm1_i = h_tm1 * rec_dp_mask[0]\n",
        "        h_tm1_f = h_tm1 * rec_dp_mask[1]\n",
        "        h_tm1_c = h_tm1 * rec_dp_mask[2]\n",
        "        h_tm1_o = h_tm1 * rec_dp_mask[3]\n",
        "      else:\n",
        "        h_tm1_i = h_tm1\n",
        "        h_tm1_f = h_tm1\n",
        "        h_tm1_c = h_tm1\n",
        "        h_tm1_o = h_tm1\n",
        "      x = (x_i, x_f, x_c, x_o)\n",
        "      h_tm1 = (h_tm1_i, h_tm1_f, h_tm1_c, h_tm1_o)\n",
        "      c, o = self._compute_carry_and_output(x, h_tm1, c_tm1)\n",
        "    else:\n",
        "      if 0. < self.dropout < 1.:\n",
        "        inputs = inputs * dp_mask[0]\n",
        "      z = backend.dot(inputs, self.kernel)\n",
        "      z += backend.dot(h_tm1, self.recurrent_kernel)\n",
        "      if self.use_bias:\n",
        "        z = backend.bias_add(z, self.bias)\n",
        "\n",
        "      z = array_ops.split(z, num_or_size_splits=4, axis=1)\n",
        "      c, o = self._compute_carry_and_output_fused(z, c_tm1)\n",
        "\n",
        "    h = o * self.activation(c)\n",
        "    return h, [h, c]\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        'units':\n",
        "            self.units,\n",
        "        'activation':\n",
        "            activations.serialize(self.activation),\n",
        "        'recurrent_activation':\n",
        "            activations.serialize(self.recurrent_activation),\n",
        "        'use_bias':\n",
        "            self.use_bias,\n",
        "        'kernel_initializer':\n",
        "            initializers.serialize(self.kernel_initializer),\n",
        "        'recurrent_initializer':\n",
        "            initializers.serialize(self.recurrent_initializer),\n",
        "        'bias_initializer':\n",
        "            initializers.serialize(self.bias_initializer),\n",
        "        'unit_forget_bias':\n",
        "            self.unit_forget_bias,\n",
        "        'kernel_regularizer':\n",
        "            regularizers.serialize(self.kernel_regularizer),\n",
        "        'recurrent_regularizer':\n",
        "            regularizers.serialize(self.recurrent_regularizer),\n",
        "        'bias_regularizer':\n",
        "            regularizers.serialize(self.bias_regularizer),\n",
        "        'kernel_constraint':\n",
        "            constraints.serialize(self.kernel_constraint),\n",
        "        'recurrent_constraint':\n",
        "            constraints.serialize(self.recurrent_constraint),\n",
        "        'bias_constraint':\n",
        "            constraints.serialize(self.bias_constraint),\n",
        "        'dropout':\n",
        "            self.dropout,\n",
        "        'recurrent_dropout':\n",
        "            self.recurrent_dropout,\n",
        "        'implementation':\n",
        "            self.implementation\n",
        "    }\n",
        "    config.update(_config_for_enable_caching_device(self))\n",
        "    base_config = super(LSTMCell, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
        "    return list(_generate_zero_filled_state_for_cell(\n",
        "        self, inputs, batch_size, dtype))\n",
        "\n",
        "@keras_export(v1=['keras.layers.LSTM'])\n",
        "class LSTM(RNN):\n",
        "\n",
        "  def __init__(self,\n",
        "               units,\n",
        "               activation='tanh',\n",
        "               recurrent_activation='hard_sigmoid',\n",
        "               use_bias=True,\n",
        "               kernel_initializer='glorot_uniform',\n",
        "               recurrent_initializer='orthogonal',\n",
        "               bias_initializer='zeros',\n",
        "               unit_forget_bias=True,\n",
        "               kernel_regularizer=None,\n",
        "               recurrent_regularizer=None,\n",
        "               bias_regularizer=None,\n",
        "               activity_regularizer=None,\n",
        "               kernel_constraint=None,\n",
        "               recurrent_constraint=None,\n",
        "               bias_constraint=None,\n",
        "               dropout=0.,\n",
        "               recurrent_dropout=0.,\n",
        "               return_sequences=False,\n",
        "               return_state=False,\n",
        "               go_backwards=False,\n",
        "               stateful=False,\n",
        "               unroll=False,\n",
        "               **kwargs):\n",
        "    implementation = kwargs.pop('implementation', 1)\n",
        "    if implementation == 0:\n",
        "      logging.warning('warning')\n",
        "    if 'enable_caching_device' in kwargs:\n",
        "      cell_kwargs = {'enable_caching_device':\n",
        "                     kwargs.pop('enable_caching_device')}\n",
        "    else:\n",
        "      cell_kwargs = {}\n",
        "    cell = LSTMCell(\n",
        "        units,\n",
        "        activation=activation,\n",
        "        recurrent_activation=recurrent_activation,\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=kernel_initializer,\n",
        "        recurrent_initializer=recurrent_initializer,\n",
        "        unit_forget_bias=unit_forget_bias,\n",
        "        bias_initializer=bias_initializer,\n",
        "        kernel_regularizer=kernel_regularizer,\n",
        "        recurrent_regularizer=recurrent_regularizer,\n",
        "        bias_regularizer=bias_regularizer,\n",
        "        kernel_constraint=kernel_constraint,\n",
        "        recurrent_constraint=recurrent_constraint,\n",
        "        bias_constraint=bias_constraint,\n",
        "        dropout=dropout,\n",
        "        recurrent_dropout=recurrent_dropout,\n",
        "        implementation=implementation,\n",
        "        dtype=kwargs.get('dtype'),\n",
        "        trainable=kwargs.get('trainable', True),\n",
        "        **cell_kwargs)\n",
        "    super(LSTM, self).__init__(\n",
        "        cell,\n",
        "        return_sequences=return_sequences,\n",
        "        return_state=return_state,\n",
        "        go_backwards=go_backwards,\n",
        "        stateful=stateful,\n",
        "        unroll=unroll,\n",
        "        **kwargs)\n",
        "    self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "    self.input_spec = [InputSpec(ndim=3)]\n",
        "\n",
        "  def call(self, inputs, mask=None, training=None, initial_state=None):\n",
        "    return super(LSTM, self).call(\n",
        "        inputs, mask=mask, training=training, initial_state=initial_state)\n",
        "\n",
        "  @property\n",
        "  def units(self):\n",
        "    return self.cell.units\n",
        "\n",
        "  @property\n",
        "  def activation(self):\n",
        "    return self.cell.activation\n",
        "\n",
        "  @property\n",
        "  def recurrent_activation(self):\n",
        "    return self.cell.recurrent_activation\n",
        "\n",
        "  @property\n",
        "  def use_bias(self):\n",
        "    return self.cell.use_bias\n",
        "\n",
        "  @property\n",
        "  def kernel_initializer(self):\n",
        "    return self.cell.kernel_initializer\n",
        "\n",
        "  @property\n",
        "  def recurrent_initializer(self):\n",
        "    return self.cell.recurrent_initializer\n",
        "\n",
        "  @property\n",
        "  def bias_initializer(self):\n",
        "    return self.cell.bias_initializer\n",
        "\n",
        "  @property\n",
        "  def unit_forget_bias(self):\n",
        "    return self.cell.unit_forget_bias\n",
        "\n",
        "  @property\n",
        "  def kernel_regularizer(self):\n",
        "    return self.cell.kernel_regularizer\n",
        "\n",
        "  @property\n",
        "  def recurrent_regularizer(self):\n",
        "    return self.cell.recurrent_regularizer\n",
        "\n",
        "  @property\n",
        "  def bias_regularizer(self):\n",
        "    return self.cell.bias_regularizer\n",
        "\n",
        "  @property\n",
        "  def kernel_constraint(self):\n",
        "    return self.cell.kernel_constraint\n",
        "\n",
        "  @property\n",
        "  def recurrent_constraint(self):\n",
        "    return self.cell.recurrent_constraint\n",
        "\n",
        "  @property\n",
        "  def bias_constraint(self):\n",
        "    return self.cell.bias_constraint\n",
        "\n",
        "  @property\n",
        "  def dropout(self):\n",
        "    return self.cell.dropout\n",
        "\n",
        "  @property\n",
        "  def recurrent_dropout(self):\n",
        "    return self.cell.recurrent_dropout\n",
        "\n",
        "  @property\n",
        "  def implementation(self):\n",
        "    return self.cell.implementation\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {\n",
        "        'units':\n",
        "            self.units,\n",
        "        'activation':\n",
        "            activations.serialize(self.activation),\n",
        "        'recurrent_activation':\n",
        "            activations.serialize(self.recurrent_activation),\n",
        "        'use_bias':\n",
        "            self.use_bias,\n",
        "        'kernel_initializer':\n",
        "            initializers.serialize(self.kernel_initializer),\n",
        "        'recurrent_initializer':\n",
        "            initializers.serialize(self.recurrent_initializer),\n",
        "        'bias_initializer':\n",
        "            initializers.serialize(self.bias_initializer),\n",
        "        'unit_forget_bias':\n",
        "            self.unit_forget_bias,\n",
        "        'kernel_regularizer':\n",
        "            regularizers.serialize(self.kernel_regularizer),\n",
        "        'recurrent_regularizer':\n",
        "            regularizers.serialize(self.recurrent_regularizer),\n",
        "        'bias_regularizer':\n",
        "            regularizers.serialize(self.bias_regularizer),\n",
        "        'activity_regularizer':\n",
        "            regularizers.serialize(self.activity_regularizer),\n",
        "        'kernel_constraint':\n",
        "            constraints.serialize(self.kernel_constraint),\n",
        "        'recurrent_constraint':\n",
        "            constraints.serialize(self.recurrent_constraint),\n",
        "        'bias_constraint':\n",
        "            constraints.serialize(self.bias_constraint),\n",
        "        'dropout':\n",
        "            self.dropout,\n",
        "        'recurrent_dropout':\n",
        "            self.recurrent_dropout,\n",
        "        'implementation':\n",
        "            self.implementation\n",
        "    }\n",
        "    config.update(_config_for_enable_caching_device(self.cell))\n",
        "    base_config = super(LSTM, self).get_config()\n",
        "    del base_config['cell']\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  @classmethod\n",
        "  def from_config(cls, config):\n",
        "    if 'implementation' in config and config['implementation'] == 0:\n",
        "      config['implementation'] = 1\n",
        "    return cls(**config)\n",
        "\n",
        "\n",
        "def _generate_dropout_mask(ones, rate, training=None, count=1):\n",
        "  def dropped_inputs():\n",
        "    return backend.dropout(ones, rate)\n",
        "\n",
        "  if count > 1:\n",
        "    return [\n",
        "        backend.in_train_phase(dropped_inputs, ones, training=training)\n",
        "        for _ in range(count)\n",
        "    ]\n",
        "  return backend.in_train_phase(dropped_inputs, ones, training=training)\n",
        "\n",
        "\n",
        "def _standardize_args(inputs, initial_state, constants, num_constants):\n",
        "\n",
        "  if isinstance(inputs, list):\n",
        "    assert initial_state is None and constants is None\n",
        "    if num_constants:\n",
        "      constants = inputs[-num_constants:]\n",
        "      inputs = inputs[:-num_constants]\n",
        "    if len(inputs) > 1:\n",
        "      initial_state = inputs[1:]\n",
        "      inputs = inputs[:1]\n",
        "\n",
        "    if len(inputs) > 1:\n",
        "      inputs = tuple(inputs)\n",
        "    else:\n",
        "      inputs = inputs[0]\n",
        "\n",
        "  def to_list_or_none(x):\n",
        "    if x is None or isinstance(x, list):\n",
        "      return x\n",
        "    if isinstance(x, tuple):\n",
        "      return list(x)\n",
        "    return [x]\n",
        "\n",
        "  initial_state = to_list_or_none(initial_state)\n",
        "  constants = to_list_or_none(constants)\n",
        "\n",
        "  return inputs, initial_state, constants\n",
        "\n",
        "\n",
        "def _is_multiple_state(state_size):\n",
        "  return (hasattr(state_size, '__len__') and\n",
        "          not isinstance(state_size, tensor_shape.TensorShape))\n",
        "\n",
        "\n",
        "def _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype):\n",
        "  if inputs is not None:\n",
        "    batch_size = array_ops.shape(inputs)[0]\n",
        "    dtype = inputs.dtype\n",
        "  return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\n",
        "\n",
        "\n",
        "def _generate_zero_filled_state(batch_size_tensor, state_size, dtype):\n",
        "  if batch_size_tensor is None or dtype is None:\n",
        "    raise ValueError(\n",
        "        'error'.format(batch_size_tensor, dtype))\n",
        "\n",
        "  def create_zeros(unnested_state_size):\n",
        "    flat_dims = tensor_shape.TensorShape(unnested_state_size).as_list()\n",
        "    init_state_size = [batch_size_tensor] + flat_dims\n",
        "    return array_ops.zeros(init_state_size, dtype=dtype)\n",
        "\n",
        "  if nest.is_nested(state_size):\n",
        "    return nest.map_structure(create_zeros, state_size)\n",
        "  else:\n",
        "    return create_zeros(state_size)\n",
        "\n",
        "\n",
        "def _caching_device(rnn_cell):\n",
        "\n",
        "  if context.executing_eagerly():\n",
        "    return None\n",
        "  if not getattr(rnn_cell, '_enable_caching_device', False):\n",
        "    return None\n",
        "  if control_flow_util.IsInWhileLoop(ops.get_default_graph()):\n",
        "    logging.warning(\n",
        "        'warning')\n",
        "    return None\n",
        "  if (rnn_cell._dtype_policy.compute_dtype !=\n",
        "      rnn_cell._dtype_policy.variable_dtype):\n",
        "    logging.warning(\n",
        "        'warning')\n",
        "    return None\n",
        "  return lambda op: op.device\n",
        "\n",
        "def _config_for_enable_caching_device(rnn_cell):\n",
        "  default_enable_caching_device = ops.executing_eagerly_outside_functions()\n",
        "  if rnn_cell._enable_caching_device != default_enable_caching_device:\n",
        "    return {'enable_caching_device': rnn_cell._enable_caching_device}\n",
        "  return {}"
      ],
      "metadata": {
        "id": "2wZDsIfRJ15a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed\n",
        "seed(10)\n",
        "tf.random.set_seed(10)"
      ],
      "metadata": {
        "id": "6BDGc9T-zx_q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sample_data/walmart_cleaned.csv')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "-cooieUQz2pj",
        "outputId": "8af4d7a3-f1ee-46b4-c27b-9ce4a221a343"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Store        Date  IsHoliday  Dept  Weekly_Sales  Temperature  \\\n",
              "0           0      1  2010-02-05          0   1.0      24924.50        42.31   \n",
              "1           1      1  2010-02-05          0  26.0      11737.12        42.31   \n",
              "2           2      1  2010-02-05          0  17.0      13223.76        42.31   \n",
              "3           3      1  2010-02-05          0  45.0         37.44        42.31   \n",
              "4           4      1  2010-02-05          0  28.0       1085.29        42.31   \n",
              "\n",
              "   Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5  \\\n",
              "0       2.572        0.0        0.0        0.0        0.0        0.0   \n",
              "1       2.572        0.0        0.0        0.0        0.0        0.0   \n",
              "2       2.572        0.0        0.0        0.0        0.0        0.0   \n",
              "3       2.572        0.0        0.0        0.0        0.0        0.0   \n",
              "4       2.572        0.0        0.0        0.0        0.0        0.0   \n",
              "\n",
              "          CPI  Unemployment  Type    Size  \n",
              "0  211.096358         8.106     3  151315  \n",
              "1  211.096358         8.106     3  151315  \n",
              "2  211.096358         8.106     3  151315  \n",
              "3  211.096358         8.106     3  151315  \n",
              "4  211.096358         8.106     3  151315  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3bb995c-9100-41c7-a4da-55249122c30d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Store</th>\n",
              "      <th>Date</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>Type</th>\n",
              "      <th>Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>24924.50</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "      <td>3</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>11737.12</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "      <td>3</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>13223.76</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "      <td>3</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>37.44</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "      <td>3</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-05</td>\n",
              "      <td>0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>1085.29</td>\n",
              "      <td>42.31</td>\n",
              "      <td>2.572</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>211.096358</td>\n",
              "      <td>8.106</td>\n",
              "      <td>3</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3bb995c-9100-41c7-a4da-55249122c30d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3bb995c-9100-41c7-a4da-55249122c30d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3bb995c-9100-41c7-a4da-55249122c30d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe().round().T.style.bar(subset=['mean'], color='#205ff2')\\\n",
        "                            .background_gradient(subset=['std'], cmap='Reds')\\\n",
        "                            .background_gradient(subset=['50%'], cmap='coolwarm')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "ozVOZWOB0e7V",
        "outputId": "5b850684-a0be-4917-832c-dc68236f2de6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f91e9335f50>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_5cc7c_row0_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#205ff2 100.0%, transparent 100.0%);\n",
              "}\n",
              "#T_5cc7c_row0_col2 {\n",
              "  background-color: #67000d;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_5cc7c_row0_col5 {\n",
              "  background-color: #b40426;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_5cc7c_row1_col1, #T_5cc7c_row3_col1, #T_5cc7c_row5_col1, #T_5cc7c_row6_col1, #T_5cc7c_row13_col1, #T_5cc7c_row14_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#205ff2 0.0%, transparent 0.0%);\n",
              "}\n",
              "#T_5cc7c_row1_col2, #T_5cc7c_row2_col2, #T_5cc7c_row3_col2, #T_5cc7c_row5_col2, #T_5cc7c_row6_col2, #T_5cc7c_row12_col2, #T_5cc7c_row13_col2, #T_5cc7c_row14_col2 {\n",
              "  background-color: #fff5f0;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_5cc7c_row1_col5, #T_5cc7c_row2_col5, #T_5cc7c_row3_col5, #T_5cc7c_row5_col5, #T_5cc7c_row6_col5, #T_5cc7c_row7_col5, #T_5cc7c_row8_col5, #T_5cc7c_row9_col5, #T_5cc7c_row10_col5, #T_5cc7c_row11_col5, #T_5cc7c_row12_col5, #T_5cc7c_row13_col5, #T_5cc7c_row14_col5 {\n",
              "  background-color: #3b4cc0;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_5cc7c_row2_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "}\n",
              "#T_5cc7c_row4_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#205ff2 7.6%, transparent 7.6%);\n",
              "}\n",
              "#T_5cc7c_row4_col2 {\n",
              "  background-color: #fdcebb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_5cc7c_row4_col5 {\n",
              "  background-color: #455cce;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_5cc7c_row7_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#205ff2 1.2%, transparent 1.2%);\n",
              "}\n",
              "#T_5cc7c_row7_col2 {\n",
              "  background-color: #ffede5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_5cc7c_row8_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#205ff2 0.4%, transparent 0.4%);\n",
              "}\n",
              "#T_5cc7c_row8_col2 {\n",
              "  background-color: #ffeee7;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_5cc7c_row9_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#205ff2 0.2%, transparent 0.2%);\n",
              "}\n",
              "#T_5cc7c_row9_col2 {\n",
              "  background-color: #ffeee6;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_5cc7c_row10_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#205ff2 0.5%, transparent 0.5%);\n",
              "}\n",
              "#T_5cc7c_row10_col2, #T_5cc7c_row11_col2 {\n",
              "  background-color: #fff0e8;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_5cc7c_row11_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#205ff2 0.8%, transparent 0.8%);\n",
              "}\n",
              "#T_5cc7c_row12_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#205ff2 0.1%, transparent 0.1%);\n",
              "}\n",
              "#T_5cc7c_row15_col1 {\n",
              "  width: 10em;\n",
              "  height: 80%;\n",
              "  background: linear-gradient(90deg,#205ff2 64.6%, transparent 64.6%);\n",
              "}\n",
              "#T_5cc7c_row15_col2 {\n",
              "  background-color: #fb6b4b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_5cc7c_row15_col5 {\n",
              "  background-color: #f7b99e;\n",
              "  color: #000000;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_5cc7c_\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th class=\"col_heading level0 col0\" >count</th>\n",
              "      <th class=\"col_heading level0 col1\" >mean</th>\n",
              "      <th class=\"col_heading level0 col2\" >std</th>\n",
              "      <th class=\"col_heading level0 col3\" >min</th>\n",
              "      <th class=\"col_heading level0 col4\" >25%</th>\n",
              "      <th class=\"col_heading level0 col5\" >50%</th>\n",
              "      <th class=\"col_heading level0 col6\" >75%</th>\n",
              "      <th class=\"col_heading level0 col7\" >max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row0\" class=\"row_heading level0 row0\" >Unnamed: 0</th>\n",
              "      <td id=\"T_5cc7c_row0_col0\" class=\"data row0 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row0_col1\" class=\"data row0 col1\" >211611.000000</td>\n",
              "      <td id=\"T_5cc7c_row0_col2\" class=\"data row0 col2\" >122195.000000</td>\n",
              "      <td id=\"T_5cc7c_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row0_col4\" class=\"data row0 col4\" >105782.000000</td>\n",
              "      <td id=\"T_5cc7c_row0_col5\" class=\"data row0 col5\" >211604.000000</td>\n",
              "      <td id=\"T_5cc7c_row0_col6\" class=\"data row0 col6\" >317425.000000</td>\n",
              "      <td id=\"T_5cc7c_row0_col7\" class=\"data row0 col7\" >423285.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row1\" class=\"row_heading level0 row1\" >Store</th>\n",
              "      <td id=\"T_5cc7c_row1_col0\" class=\"data row1 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row1_col1\" class=\"data row1 col1\" >22.000000</td>\n",
              "      <td id=\"T_5cc7c_row1_col2\" class=\"data row1 col2\" >13.000000</td>\n",
              "      <td id=\"T_5cc7c_row1_col3\" class=\"data row1 col3\" >1.000000</td>\n",
              "      <td id=\"T_5cc7c_row1_col4\" class=\"data row1 col4\" >11.000000</td>\n",
              "      <td id=\"T_5cc7c_row1_col5\" class=\"data row1 col5\" >22.000000</td>\n",
              "      <td id=\"T_5cc7c_row1_col6\" class=\"data row1 col6\" >33.000000</td>\n",
              "      <td id=\"T_5cc7c_row1_col7\" class=\"data row1 col7\" >45.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row2\" class=\"row_heading level0 row2\" >IsHoliday</th>\n",
              "      <td id=\"T_5cc7c_row2_col0\" class=\"data row2 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row2_col1\" class=\"data row2 col1\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row2_col2\" class=\"data row2 col2\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row2_col4\" class=\"data row2 col4\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row2_col5\" class=\"data row2 col5\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row2_col6\" class=\"data row2 col6\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row2_col7\" class=\"data row2 col7\" >1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row3\" class=\"row_heading level0 row3\" >Dept</th>\n",
              "      <td id=\"T_5cc7c_row3_col0\" class=\"data row3 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row3_col1\" class=\"data row3 col1\" >44.000000</td>\n",
              "      <td id=\"T_5cc7c_row3_col2\" class=\"data row3 col2\" >30.000000</td>\n",
              "      <td id=\"T_5cc7c_row3_col3\" class=\"data row3 col3\" >1.000000</td>\n",
              "      <td id=\"T_5cc7c_row3_col4\" class=\"data row3 col4\" >18.000000</td>\n",
              "      <td id=\"T_5cc7c_row3_col5\" class=\"data row3 col5\" >37.000000</td>\n",
              "      <td id=\"T_5cc7c_row3_col6\" class=\"data row3 col6\" >74.000000</td>\n",
              "      <td id=\"T_5cc7c_row3_col7\" class=\"data row3 col7\" >99.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row4\" class=\"row_heading level0 row4\" >Weekly_Sales</th>\n",
              "      <td id=\"T_5cc7c_row4_col0\" class=\"data row4 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row4_col1\" class=\"data row4 col1\" >15981.000000</td>\n",
              "      <td id=\"T_5cc7c_row4_col2\" class=\"data row4 col2\" >22711.000000</td>\n",
              "      <td id=\"T_5cc7c_row4_col3\" class=\"data row4 col3\" >-4989.000000</td>\n",
              "      <td id=\"T_5cc7c_row4_col4\" class=\"data row4 col4\" >2080.000000</td>\n",
              "      <td id=\"T_5cc7c_row4_col5\" class=\"data row4 col5\" >7612.000000</td>\n",
              "      <td id=\"T_5cc7c_row4_col6\" class=\"data row4 col6\" >20206.000000</td>\n",
              "      <td id=\"T_5cc7c_row4_col7\" class=\"data row4 col7\" >693099.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row5\" class=\"row_heading level0 row5\" >Temperature</th>\n",
              "      <td id=\"T_5cc7c_row5_col0\" class=\"data row5 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row5_col1\" class=\"data row5 col1\" >60.000000</td>\n",
              "      <td id=\"T_5cc7c_row5_col2\" class=\"data row5 col2\" >18.000000</td>\n",
              "      <td id=\"T_5cc7c_row5_col3\" class=\"data row5 col3\" >-2.000000</td>\n",
              "      <td id=\"T_5cc7c_row5_col4\" class=\"data row5 col4\" >47.000000</td>\n",
              "      <td id=\"T_5cc7c_row5_col5\" class=\"data row5 col5\" >62.000000</td>\n",
              "      <td id=\"T_5cc7c_row5_col6\" class=\"data row5 col6\" >74.000000</td>\n",
              "      <td id=\"T_5cc7c_row5_col7\" class=\"data row5 col7\" >100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row6\" class=\"row_heading level0 row6\" >Fuel_Price</th>\n",
              "      <td id=\"T_5cc7c_row6_col0\" class=\"data row6 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row6_col1\" class=\"data row6 col1\" >3.000000</td>\n",
              "      <td id=\"T_5cc7c_row6_col2\" class=\"data row6 col2\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row6_col3\" class=\"data row6 col3\" >2.000000</td>\n",
              "      <td id=\"T_5cc7c_row6_col4\" class=\"data row6 col4\" >3.000000</td>\n",
              "      <td id=\"T_5cc7c_row6_col5\" class=\"data row6 col5\" >3.000000</td>\n",
              "      <td id=\"T_5cc7c_row6_col6\" class=\"data row6 col6\" >4.000000</td>\n",
              "      <td id=\"T_5cc7c_row6_col7\" class=\"data row6 col7\" >4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row7\" class=\"row_heading level0 row7\" >MarkDown1</th>\n",
              "      <td id=\"T_5cc7c_row7_col0\" class=\"data row7 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row7_col1\" class=\"data row7 col1\" >2590.000000</td>\n",
              "      <td id=\"T_5cc7c_row7_col2\" class=\"data row7 col2\" >6052.000000</td>\n",
              "      <td id=\"T_5cc7c_row7_col3\" class=\"data row7 col3\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row7_col4\" class=\"data row7 col4\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row7_col5\" class=\"data row7 col5\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row7_col6\" class=\"data row7 col6\" >2809.000000</td>\n",
              "      <td id=\"T_5cc7c_row7_col7\" class=\"data row7 col7\" >88647.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row8\" class=\"row_heading level0 row8\" >MarkDown2</th>\n",
              "      <td id=\"T_5cc7c_row8_col0\" class=\"data row8 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row8_col1\" class=\"data row8 col1\" >880.000000</td>\n",
              "      <td id=\"T_5cc7c_row8_col2\" class=\"data row8 col2\" >5085.000000</td>\n",
              "      <td id=\"T_5cc7c_row8_col3\" class=\"data row8 col3\" >-266.000000</td>\n",
              "      <td id=\"T_5cc7c_row8_col4\" class=\"data row8 col4\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row8_col5\" class=\"data row8 col5\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row8_col6\" class=\"data row8 col6\" >2.000000</td>\n",
              "      <td id=\"T_5cc7c_row8_col7\" class=\"data row8 col7\" >104520.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row9\" class=\"row_heading level0 row9\" >MarkDown3</th>\n",
              "      <td id=\"T_5cc7c_row9_col0\" class=\"data row9 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row9_col1\" class=\"data row9 col1\" >468.000000</td>\n",
              "      <td id=\"T_5cc7c_row9_col2\" class=\"data row9 col2\" >5529.000000</td>\n",
              "      <td id=\"T_5cc7c_row9_col3\" class=\"data row9 col3\" >-29.000000</td>\n",
              "      <td id=\"T_5cc7c_row9_col4\" class=\"data row9 col4\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row9_col5\" class=\"data row9 col5\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row9_col6\" class=\"data row9 col6\" >5.000000</td>\n",
              "      <td id=\"T_5cc7c_row9_col7\" class=\"data row9 col7\" >141631.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row10\" class=\"row_heading level0 row10\" >MarkDown4</th>\n",
              "      <td id=\"T_5cc7c_row10_col0\" class=\"data row10 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row10_col1\" class=\"data row10 col1\" >1083.000000</td>\n",
              "      <td id=\"T_5cc7c_row10_col2\" class=\"data row10 col2\" >3895.000000</td>\n",
              "      <td id=\"T_5cc7c_row10_col3\" class=\"data row10 col3\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row10_col4\" class=\"data row10 col4\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row10_col5\" class=\"data row10 col5\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row10_col6\" class=\"data row10 col6\" >425.000000</td>\n",
              "      <td id=\"T_5cc7c_row10_col7\" class=\"data row10 col7\" >67475.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row11\" class=\"row_heading level0 row11\" >MarkDown5</th>\n",
              "      <td id=\"T_5cc7c_row11_col0\" class=\"data row11 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row11_col1\" class=\"data row11 col1\" >1663.000000</td>\n",
              "      <td id=\"T_5cc7c_row11_col2\" class=\"data row11 col2\" >4208.000000</td>\n",
              "      <td id=\"T_5cc7c_row11_col3\" class=\"data row11 col3\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row11_col4\" class=\"data row11 col4\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row11_col5\" class=\"data row11 col5\" >0.000000</td>\n",
              "      <td id=\"T_5cc7c_row11_col6\" class=\"data row11 col6\" >2168.000000</td>\n",
              "      <td id=\"T_5cc7c_row11_col7\" class=\"data row11 col7\" >108519.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row12\" class=\"row_heading level0 row12\" >CPI</th>\n",
              "      <td id=\"T_5cc7c_row12_col0\" class=\"data row12 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row12_col1\" class=\"data row12 col1\" >171.000000</td>\n",
              "      <td id=\"T_5cc7c_row12_col2\" class=\"data row12 col2\" >39.000000</td>\n",
              "      <td id=\"T_5cc7c_row12_col3\" class=\"data row12 col3\" >126.000000</td>\n",
              "      <td id=\"T_5cc7c_row12_col4\" class=\"data row12 col4\" >132.000000</td>\n",
              "      <td id=\"T_5cc7c_row12_col5\" class=\"data row12 col5\" >182.000000</td>\n",
              "      <td id=\"T_5cc7c_row12_col6\" class=\"data row12 col6\" >212.000000</td>\n",
              "      <td id=\"T_5cc7c_row12_col7\" class=\"data row12 col7\" >227.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row13\" class=\"row_heading level0 row13\" >Unemployment</th>\n",
              "      <td id=\"T_5cc7c_row13_col0\" class=\"data row13 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row13_col1\" class=\"data row13 col1\" >8.000000</td>\n",
              "      <td id=\"T_5cc7c_row13_col2\" class=\"data row13 col2\" >2.000000</td>\n",
              "      <td id=\"T_5cc7c_row13_col3\" class=\"data row13 col3\" >4.000000</td>\n",
              "      <td id=\"T_5cc7c_row13_col4\" class=\"data row13 col4\" >7.000000</td>\n",
              "      <td id=\"T_5cc7c_row13_col5\" class=\"data row13 col5\" >8.000000</td>\n",
              "      <td id=\"T_5cc7c_row13_col6\" class=\"data row13 col6\" >9.000000</td>\n",
              "      <td id=\"T_5cc7c_row13_col7\" class=\"data row13 col7\" >14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row14\" class=\"row_heading level0 row14\" >Type</th>\n",
              "      <td id=\"T_5cc7c_row14_col0\" class=\"data row14 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row14_col1\" class=\"data row14 col1\" >2.000000</td>\n",
              "      <td id=\"T_5cc7c_row14_col2\" class=\"data row14 col2\" >1.000000</td>\n",
              "      <td id=\"T_5cc7c_row14_col3\" class=\"data row14 col3\" >1.000000</td>\n",
              "      <td id=\"T_5cc7c_row14_col4\" class=\"data row14 col4\" >2.000000</td>\n",
              "      <td id=\"T_5cc7c_row14_col5\" class=\"data row14 col5\" >3.000000</td>\n",
              "      <td id=\"T_5cc7c_row14_col6\" class=\"data row14 col6\" >3.000000</td>\n",
              "      <td id=\"T_5cc7c_row14_col7\" class=\"data row14 col7\" >3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_5cc7c_level0_row15\" class=\"row_heading level0 row15\" >Size</th>\n",
              "      <td id=\"T_5cc7c_row15_col0\" class=\"data row15 col0\" >421570.000000</td>\n",
              "      <td id=\"T_5cc7c_row15_col1\" class=\"data row15 col1\" >136728.000000</td>\n",
              "      <td id=\"T_5cc7c_row15_col2\" class=\"data row15 col2\" >60981.000000</td>\n",
              "      <td id=\"T_5cc7c_row15_col3\" class=\"data row15 col3\" >34875.000000</td>\n",
              "      <td id=\"T_5cc7c_row15_col4\" class=\"data row15 col4\" >93638.000000</td>\n",
              "      <td id=\"T_5cc7c_row15_col5\" class=\"data row15 col5\" >140167.000000</td>\n",
              "      <td id=\"T_5cc7c_row15_col6\" class=\"data row15 col6\" >202505.000000</td>\n",
              "      <td id=\"T_5cc7c_row15_col7\" class=\"data row15 col7\" >219622.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Date'] = pd.to_datetime(data['Date'])"
      ],
      "metadata": {
        "id": "FMEfamTJ0lE4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_dept_table = pd.pivot_table(data, index='Store', columns='Dept',\n",
        "                                  values='Weekly_Sales', aggfunc=np.mean)\n",
        "display(store_dept_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pKpdwVce0niZ",
        "outputId": "5a415d7c-50b2-4fa2-b402-57403789d9ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dept           1.0            2.0           3.0           4.0           5.0   \\\n",
              "Store                                                                          \n",
              "1      22513.322937   46102.090420  13150.478042  36964.154476  24257.941119   \n",
              "2      30777.980769   65912.922517  17476.563357  45607.666573  30555.315315   \n",
              "3       7328.621049   16841.775664   5509.300769   8434.186503  11695.366573   \n",
              "4      36979.940070   93639.315385  19012.491678  56603.400140  45668.406783   \n",
              "5       9774.553077   12317.953287   4101.085175   9860.806783   6699.202238   \n",
              "6      23867.553776   50269.437273  16806.638811  34187.366503  34465.307622   \n",
              "7       9542.801259   22603.690769   8633.536923  14950.518601  13860.350490   \n",
              "8      14789.827343   35729.821748  10683.305105  21089.309301  19838.849231   \n",
              "9      11846.558252   24969.477413   7497.356783  17165.947762  19282.746014   \n",
              "10     39925.138951  109795.291469  32086.181469  48579.826364  58373.460280   \n",
              "11     18860.911958   57114.326224  17628.778671  28837.744545  36663.363916   \n",
              "12     17330.087622   74494.846224  17535.251678  26673.788182  27756.204615   \n",
              "13     47020.455455   76339.960000  26116.623706  42563.275455  56786.934755   \n",
              "14     30611.783357   77704.857972  19418.273986  52936.323287  33468.325035   \n",
              "15     13845.747832   26317.410769  10470.811958  13082.172448  16465.706993   \n",
              "16     11352.479371   23549.144965   7635.427273  14748.078112  13494.538671   \n",
              "17     22801.609161   42231.844406  19278.955035  23961.357273  27082.325594   \n",
              "18     21988.356224   63665.139510  16392.980490  26775.207203  22933.954965   \n",
              "19     21504.029161   50841.072937  18414.224476  31365.545315  28759.223846   \n",
              "20     40545.473217   78251.249930  15490.971259  51456.376643  41647.786503   \n",
              "21     14950.049231   47780.599161  14607.126923  19354.728042  16090.874545   \n",
              "22     21493.271119   53361.851888  13150.979510  32104.132378  23187.335105   \n",
              "23     33186.460559   70522.580140  19912.564755  27324.303077  36895.869021   \n",
              "24     18859.023357   40797.169301  11825.589021  29245.357552  29178.058811   \n",
              "25     20145.897483   36871.310559  11788.130979  20351.455455  12422.996434   \n",
              "26     19402.762937   27398.030979   7357.400769  24498.113846  17589.532587   \n",
              "27     30437.976224   79001.049161  20226.734615  43596.933916  28059.038252   \n",
              "28     20180.453986   57751.274336  12562.223287  27980.817203  28221.618392   \n",
              "29     15504.699580   25181.662727   7995.955804  14326.216224  12931.821259   \n",
              "30      9788.376643   12974.464476    739.981888  13216.100909    405.565944   \n",
              "31     17356.652448   58512.131538  10616.675944  34848.899231  18715.630769   \n",
              "32     22852.639510   50323.497343  15472.540140  28137.154965  20748.371888   \n",
              "33      2379.086573    7471.425105    283.950140   6107.616014    112.728310   \n",
              "34     19947.573077   34916.225874   8377.376434  19791.509021  21633.900559   \n",
              "35     17082.647902   45578.456224  14308.382797  19495.631119  24858.433706   \n",
              "36      2239.227413   13416.025664    381.324266   9873.505105    314.753982   \n",
              "37     11024.235874   16511.446224   1297.862028  17614.013636   1137.631189   \n",
              "38      6923.538531   10986.172657    498.700210  10669.501329    397.418322   \n",
              "39     21925.021189   67338.429371  20569.701608  44807.515105  24043.436783   \n",
              "40     18794.578811   26702.705175   6489.030350  24386.750559  17689.671678   \n",
              "41     23205.259930   48349.828951  17021.833357  30538.574895  25513.943776   \n",
              "42     10375.148392   15976.902448    814.451189  14885.264755   1052.296783   \n",
              "43      7549.109021   20722.851469    999.648881  18227.382168    575.417326   \n",
              "44      8049.992308    9377.273007    571.016713   7403.959580    960.670490   \n",
              "45     17745.916014   35800.912448   9508.014965  24229.873147  16107.063077   \n",
              "\n",
              "Dept           6.0           7.0           8.0           9.0           10.0  \\\n",
              "Store                                                                         \n",
              "1       4801.780140  24566.487413  35718.257622  28062.052238  31033.386364   \n",
              "2       6808.382517  40477.837063  58707.369441  34375.864476  38845.854476   \n",
              "3       2012.411818  10044.341608   8310.254196   9062.007692  10871.944126   \n",
              "4       8241.777692  50728.151399  62949.723776  34437.170979  37269.667413   \n",
              "5       1191.057622   6124.484336  13735.709441   7919.805944   9783.395385   \n",
              "6       7225.566643  34526.870420  47577.719790  48271.060140  47436.477902   \n",
              "7       6329.928811  10925.757063  13970.619371  29722.736084  21136.560280   \n",
              "8       3395.425455  20268.743776  26438.524336  11792.661678  20666.433776   \n",
              "9       2806.416364  13826.694336  21424.470699  13196.569720  12810.480350   \n",
              "10     10556.550769  58964.715664  86739.846643  64436.722517  48108.063497   \n",
              "11      5925.281678  34844.108462  34415.449580  19056.162168  23449.992727   \n",
              "12      6741.174895  34242.449161  42229.665035  19553.030490  17975.211119   \n",
              "13      7886.826993  59896.738601  36238.867972  41236.445175  29431.879231   \n",
              "14      7016.829790  53256.150280  53425.359860  22025.603497  20165.667133   \n",
              "15      4244.143776  22267.220070  20416.967273  15954.692937  11524.856294   \n",
              "16      5146.038951  11544.310140  14676.778322  28990.377343  12681.776643   \n",
              "17      5944.435245  19474.770559  20110.270839  27293.658042  14165.000000   \n",
              "18      5664.913077  33152.347203  32036.582098  18589.371259  16754.599860   \n",
              "19      5948.962867  33882.926853  42613.662937  30645.018112  27622.457762   \n",
              "20      8210.745734  49394.699231  76445.061259  38243.623916  41826.467552   \n",
              "21      3988.656294  24456.825664  18238.059790  16387.963636  14695.978881   \n",
              "22      5236.811329  29068.621608  37236.347692  23452.908881  19438.354266   \n",
              "23      7393.499650  43624.067413  36710.240909  50178.361748  31155.170559   \n",
              "24      4911.185804  28788.329441  49171.841748  23246.748322  27175.089231   \n",
              "25      3760.045035  17971.439580  29858.353636  14636.113636  20202.701469   \n",
              "26      4656.670490  16287.658531  28694.950909  16556.330769  10172.815734   \n",
              "27      7730.729091  43272.914965  42181.469580  29315.697133  36757.327413   \n",
              "28      5016.258671  29228.446923  33375.575524  17930.710070  21083.404825   \n",
              "29      3289.884965  16854.082238  20680.465944  11370.866364   9400.183077   \n",
              "30        27.303937    379.771958  11733.993776     76.845352    196.116923   \n",
              "31      3489.809441  21012.438531  25277.976713  10815.516713  19911.584406   \n",
              "32      4589.748392  25375.036993  24681.349580  20739.684685  22887.257483   \n",
              "33        11.996538    392.912867   3679.792168     42.788348     80.301189   \n",
              "34      3419.062028  18055.491608  27165.013147  17224.253497  16957.163566   \n",
              "35      7256.417133  30267.589790  18416.401678  15657.032937  14818.443706   \n",
              "36        26.291579    414.428322   3417.640420    102.211739    175.052308   \n",
              "37        46.313630    824.978392  16151.397902    151.233803    387.644685   \n",
              "38        37.014855    413.539021   9485.399441     77.520350    365.364895   \n",
              "39      4911.540420  40020.492867  36130.641608  19396.117692  14919.373916   \n",
              "40      4003.068601  18898.214336  33971.532238  19065.436294  19612.629301   \n",
              "41      5267.832098  33711.105734  33729.081678  32743.470140  15194.223706   \n",
              "42         3.333333    721.913846  18238.584196    135.524056    404.596014   \n",
              "43        37.843246    516.772867  13185.211678    147.694196    507.426713   \n",
              "44        34.648722    531.034895   4963.966224     99.817273    153.792657   \n",
              "45      3554.222657  23757.771538  34050.409580  15485.885804  14245.086993   \n",
              "\n",
              "Dept   ...           90.0          91.0           92.0          93.0  \\\n",
              "Store  ...                                                             \n",
              "1      ...   82427.547832  64238.943427  135458.969510  71699.182378   \n",
              "2      ...   97611.537133  80610.380350  164840.230979  70581.977063   \n",
              "3      ...    1540.049161    318.685594    7568.280210           NaN   \n",
              "4      ...   89248.965524  66535.407203  159365.107902  67815.163007   \n",
              "5      ...    3059.520000   1457.221678    7759.205594           NaN   \n",
              "6      ...   53715.366084  45270.405175   99024.796503  41359.651189   \n",
              "7      ...   13858.405874  10263.880000   26530.890559   1328.178252   \n",
              "8      ...   39333.566154  31530.560909   60465.630000  27515.635315   \n",
              "9      ...    2981.249510    869.273287   14123.063147     21.240000   \n",
              "10     ...   14291.869790  12703.554406   50450.731958   1420.418462   \n",
              "11     ...   48995.984196  42030.370699   77392.741608  32623.853706   \n",
              "12     ...   11060.175455   6779.841469   24682.599161    562.897203   \n",
              "13     ...  115592.108042  81272.990979  162034.099301  50024.937203   \n",
              "14     ...  107174.743986  91406.434615  182527.956014  62088.622937   \n",
              "15     ...    5345.240420   3414.740909   18262.376853    422.878252   \n",
              "16     ...    6922.744685   3331.204965   20446.967832    997.032281   \n",
              "17     ...   31293.306224  12033.678951   53043.348741   3646.955664   \n",
              "18     ...   18481.394266  14124.482517   50079.623636   2113.300147   \n",
              "19     ...   67545.406434  54692.797413  113720.212937  37087.937063   \n",
              "20     ...   95858.587343  78493.190140  164633.741538  52818.583706   \n",
              "21     ...   10983.598741   6735.454126   21915.114965    663.384126   \n",
              "22     ...   21413.411608  21405.250629   51603.339091   2531.663986   \n",
              "23     ...   20814.992168  19604.867692   59604.574615   2111.610780   \n",
              "24     ...   72650.442867  52435.498252  121882.073916  37876.836853   \n",
              "25     ...   11932.596503   7767.272098   38854.460699    777.747483   \n",
              "26     ...   57016.589231  39434.281259   84988.311818  25615.331469   \n",
              "27     ...   96374.536573  66687.096573  146518.141399  54910.693776   \n",
              "28     ...   65285.952098  57575.601119   98486.960350  47923.508671   \n",
              "29     ...   10950.327972   4691.213217   25166.714266   1190.882098   \n",
              "30     ...   34622.986224  31576.583986   53256.041399  22409.698392   \n",
              "31     ...   86167.265804  70232.133566  127010.118601  57876.205664   \n",
              "32     ...   61639.637133  48368.756154  100122.929021  30732.226923   \n",
              "33     ...   24899.923147   9862.862867   34227.662867  25648.054266   \n",
              "34     ...   44338.936783  34018.102238   67782.520909  29590.111329   \n",
              "35     ...   12960.450210   7919.080140   33776.032028   1528.451469   \n",
              "36     ...   35474.191958  11097.875874   44539.564476  26103.315664   \n",
              "37     ...   44144.428112  30870.677063   59440.577133  21599.851049   \n",
              "38     ...   34765.576783  25404.860420   45314.434825  18868.919091   \n",
              "39     ...   78649.534685  60386.286014  110126.209580  39684.510000   \n",
              "40     ...   61258.202867  43256.156853   96475.753287  27532.751189   \n",
              "41     ...   70852.021818  52714.928462  115827.664056  35415.340000   \n",
              "42     ...   53384.897902  42913.221259   83497.778671  32852.632308   \n",
              "43     ...   63668.895594  34808.442168   83646.160909  36196.693217   \n",
              "44     ...   31182.601818  18169.510070   39619.563287  11029.915734   \n",
              "45     ...   23674.035245  16641.927343   48125.897762   2728.627133   \n",
              "\n",
              "Dept           94.0           95.0          96.0          97.0          98.0  \\\n",
              "Store                                                                          \n",
              "1      63180.568182  120772.062168  33251.831639  35207.348811  11827.770769   \n",
              "2      70018.672517  143588.751888  34319.063846  40697.204056  14035.400839   \n",
              "3        656.294444   15745.528252   3934.540000    343.437357     30.570833   \n",
              "4      68159.106573  147236.473706  38346.573077  39339.238951  15009.249371   \n",
              "5        411.431486   19340.693986   5985.671119    667.070315     29.976087   \n",
              "6      41701.693497   89208.786294  30450.542238  20637.667063   9728.100629   \n",
              "7        699.332522   34208.097273   1123.383217   4374.927902    260.886596   \n",
              "8      25442.578042   62951.463706     16.986667  16978.366503   6880.466434   \n",
              "9        599.112568   29575.050769   3596.107762    372.655556     27.930000   \n",
              "10       393.833168   73344.654685  11079.676643   5323.506503    198.179091   \n",
              "11     37474.038531   77487.279091  21685.298811  16596.197552   9570.351469   \n",
              "12       355.264000   43405.853357      6.441176   2394.894755    747.609860   \n",
              "13     75522.874406  136844.834056   9165.079930  27556.759231  14980.825385   \n",
              "14     64541.165664  144446.932517      5.193846  25684.497762  17768.013706   \n",
              "15       272.906250   27291.017133   2784.158881   2071.211888    273.504884   \n",
              "16       673.280928   27385.769231    126.934126   2116.696993     42.618571   \n",
              "17       855.782273   50614.958462    819.416458   7798.283427    169.379120   \n",
              "18      4880.242248   57668.251748      0.481333   5350.500432    881.150853   \n",
              "19     37643.786434   97240.503566  15860.814825  20370.269720  12884.229091   \n",
              "20     63148.334965  150613.955385     15.266875  25836.062238  19284.377343   \n",
              "21       537.663333   40379.295175      2.000000   3260.404685    111.680672   \n",
              "22       857.190894   57868.571119      6.243000   4582.594755    177.560576   \n",
              "23       374.898804   54199.088322  13168.146713   6149.684755    100.585083   \n",
              "24     51850.045105   93927.992098  13623.074615  18597.824126   9878.970140   \n",
              "25      2607.109754   43991.147692     -1.270000   2706.628252    665.919779   \n",
              "26     42544.202028   70236.827622  18596.331888  14830.084825   8025.948601   \n",
              "27     69638.930420  119519.410909  20806.990909  21268.805734  11524.137832   \n",
              "28     36164.364615   96322.113846  26288.955734  23828.861329  10673.133077   \n",
              "29       263.083012   30980.395594     11.800000   2131.676783    139.677971   \n",
              "30     24522.622587   45456.508322  19163.112028  13172.531119   3207.034685   \n",
              "31     68732.141818  106696.019231  30335.294266  31144.978112  10101.886713   \n",
              "32     48650.040979   84695.234196   2308.411818  17160.310000   7939.262378   \n",
              "33     29002.624476   27022.949161   9371.822168   5375.769510   7340.692168   \n",
              "34     37428.096923   69245.187972  19154.212308  17570.577483   7775.998182   \n",
              "35       200.270435   43286.536993     10.788333   3738.292517     68.284831   \n",
              "36     47372.151119   39735.688741  15683.341818   6469.273636   9009.943776   \n",
              "37     33656.648112   51410.551119  20375.380769  13960.701399   5286.761119   \n",
              "38     21331.411259   41793.649021  11981.676643   9902.368182   4783.086713   \n",
              "39     59830.190280  103036.757133  27089.158601  23993.406853   9767.295734   \n",
              "40     38210.900699   66572.881259  15309.077972  17131.033497   8178.371049   \n",
              "41     47218.529161   88666.468392   2883.492238  19789.219231   9371.531608   \n",
              "42     35724.612098   61205.272308  15183.474196  17495.198811   6540.721259   \n",
              "43     50769.708322   72883.223287  25058.369371  19349.989930   9594.867483   \n",
              "44     23812.046993   31100.185175   2834.139580   6636.467413   3466.077063   \n",
              "45      3690.272090   52896.166643      2.970000   6466.961888    561.239037   \n",
              "\n",
              "Dept         99.0  \n",
              "Store              \n",
              "1      306.091081  \n",
              "2      475.896905  \n",
              "3             NaN  \n",
              "4      623.182381  \n",
              "5             NaN  \n",
              "6      388.636750  \n",
              "7       15.000000  \n",
              "8      298.153714  \n",
              "9             NaN  \n",
              "10            NaN  \n",
              "11     520.938125  \n",
              "12      29.880000  \n",
              "13     732.604651  \n",
              "14     635.556047  \n",
              "15      29.880000  \n",
              "16      59.760000  \n",
              "17       2.290000  \n",
              "18      12.560000  \n",
              "19     440.374878  \n",
              "20     796.153864  \n",
              "21      29.880000  \n",
              "22      27.150000  \n",
              "23      29.880000  \n",
              "24     413.774211  \n",
              "25            NaN  \n",
              "26     221.950278  \n",
              "27     562.980000  \n",
              "28     316.605610  \n",
              "29      29.880000  \n",
              "30      -0.641818  \n",
              "31     218.742203  \n",
              "32     379.147250  \n",
              "33       0.022000  \n",
              "34     347.144324  \n",
              "35            NaN  \n",
              "36       0.020000  \n",
              "37      15.000000  \n",
              "38      25.000000  \n",
              "39     334.869756  \n",
              "40     167.374167  \n",
              "41     443.736512  \n",
              "42            NaN  \n",
              "43      26.250000  \n",
              "44       3.505000  \n",
              "45            NaN  \n",
              "\n",
              "[45 rows x 81 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa2b65bf-ff00-476e-a4b4-d74cb352327c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Dept</th>\n",
              "      <th>1.0</th>\n",
              "      <th>2.0</th>\n",
              "      <th>3.0</th>\n",
              "      <th>4.0</th>\n",
              "      <th>5.0</th>\n",
              "      <th>6.0</th>\n",
              "      <th>7.0</th>\n",
              "      <th>8.0</th>\n",
              "      <th>9.0</th>\n",
              "      <th>10.0</th>\n",
              "      <th>...</th>\n",
              "      <th>90.0</th>\n",
              "      <th>91.0</th>\n",
              "      <th>92.0</th>\n",
              "      <th>93.0</th>\n",
              "      <th>94.0</th>\n",
              "      <th>95.0</th>\n",
              "      <th>96.0</th>\n",
              "      <th>97.0</th>\n",
              "      <th>98.0</th>\n",
              "      <th>99.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Store</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22513.322937</td>\n",
              "      <td>46102.090420</td>\n",
              "      <td>13150.478042</td>\n",
              "      <td>36964.154476</td>\n",
              "      <td>24257.941119</td>\n",
              "      <td>4801.780140</td>\n",
              "      <td>24566.487413</td>\n",
              "      <td>35718.257622</td>\n",
              "      <td>28062.052238</td>\n",
              "      <td>31033.386364</td>\n",
              "      <td>...</td>\n",
              "      <td>82427.547832</td>\n",
              "      <td>64238.943427</td>\n",
              "      <td>135458.969510</td>\n",
              "      <td>71699.182378</td>\n",
              "      <td>63180.568182</td>\n",
              "      <td>120772.062168</td>\n",
              "      <td>33251.831639</td>\n",
              "      <td>35207.348811</td>\n",
              "      <td>11827.770769</td>\n",
              "      <td>306.091081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30777.980769</td>\n",
              "      <td>65912.922517</td>\n",
              "      <td>17476.563357</td>\n",
              "      <td>45607.666573</td>\n",
              "      <td>30555.315315</td>\n",
              "      <td>6808.382517</td>\n",
              "      <td>40477.837063</td>\n",
              "      <td>58707.369441</td>\n",
              "      <td>34375.864476</td>\n",
              "      <td>38845.854476</td>\n",
              "      <td>...</td>\n",
              "      <td>97611.537133</td>\n",
              "      <td>80610.380350</td>\n",
              "      <td>164840.230979</td>\n",
              "      <td>70581.977063</td>\n",
              "      <td>70018.672517</td>\n",
              "      <td>143588.751888</td>\n",
              "      <td>34319.063846</td>\n",
              "      <td>40697.204056</td>\n",
              "      <td>14035.400839</td>\n",
              "      <td>475.896905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7328.621049</td>\n",
              "      <td>16841.775664</td>\n",
              "      <td>5509.300769</td>\n",
              "      <td>8434.186503</td>\n",
              "      <td>11695.366573</td>\n",
              "      <td>2012.411818</td>\n",
              "      <td>10044.341608</td>\n",
              "      <td>8310.254196</td>\n",
              "      <td>9062.007692</td>\n",
              "      <td>10871.944126</td>\n",
              "      <td>...</td>\n",
              "      <td>1540.049161</td>\n",
              "      <td>318.685594</td>\n",
              "      <td>7568.280210</td>\n",
              "      <td>NaN</td>\n",
              "      <td>656.294444</td>\n",
              "      <td>15745.528252</td>\n",
              "      <td>3934.540000</td>\n",
              "      <td>343.437357</td>\n",
              "      <td>30.570833</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36979.940070</td>\n",
              "      <td>93639.315385</td>\n",
              "      <td>19012.491678</td>\n",
              "      <td>56603.400140</td>\n",
              "      <td>45668.406783</td>\n",
              "      <td>8241.777692</td>\n",
              "      <td>50728.151399</td>\n",
              "      <td>62949.723776</td>\n",
              "      <td>34437.170979</td>\n",
              "      <td>37269.667413</td>\n",
              "      <td>...</td>\n",
              "      <td>89248.965524</td>\n",
              "      <td>66535.407203</td>\n",
              "      <td>159365.107902</td>\n",
              "      <td>67815.163007</td>\n",
              "      <td>68159.106573</td>\n",
              "      <td>147236.473706</td>\n",
              "      <td>38346.573077</td>\n",
              "      <td>39339.238951</td>\n",
              "      <td>15009.249371</td>\n",
              "      <td>623.182381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9774.553077</td>\n",
              "      <td>12317.953287</td>\n",
              "      <td>4101.085175</td>\n",
              "      <td>9860.806783</td>\n",
              "      <td>6699.202238</td>\n",
              "      <td>1191.057622</td>\n",
              "      <td>6124.484336</td>\n",
              "      <td>13735.709441</td>\n",
              "      <td>7919.805944</td>\n",
              "      <td>9783.395385</td>\n",
              "      <td>...</td>\n",
              "      <td>3059.520000</td>\n",
              "      <td>1457.221678</td>\n",
              "      <td>7759.205594</td>\n",
              "      <td>NaN</td>\n",
              "      <td>411.431486</td>\n",
              "      <td>19340.693986</td>\n",
              "      <td>5985.671119</td>\n",
              "      <td>667.070315</td>\n",
              "      <td>29.976087</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>23867.553776</td>\n",
              "      <td>50269.437273</td>\n",
              "      <td>16806.638811</td>\n",
              "      <td>34187.366503</td>\n",
              "      <td>34465.307622</td>\n",
              "      <td>7225.566643</td>\n",
              "      <td>34526.870420</td>\n",
              "      <td>47577.719790</td>\n",
              "      <td>48271.060140</td>\n",
              "      <td>47436.477902</td>\n",
              "      <td>...</td>\n",
              "      <td>53715.366084</td>\n",
              "      <td>45270.405175</td>\n",
              "      <td>99024.796503</td>\n",
              "      <td>41359.651189</td>\n",
              "      <td>41701.693497</td>\n",
              "      <td>89208.786294</td>\n",
              "      <td>30450.542238</td>\n",
              "      <td>20637.667063</td>\n",
              "      <td>9728.100629</td>\n",
              "      <td>388.636750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9542.801259</td>\n",
              "      <td>22603.690769</td>\n",
              "      <td>8633.536923</td>\n",
              "      <td>14950.518601</td>\n",
              "      <td>13860.350490</td>\n",
              "      <td>6329.928811</td>\n",
              "      <td>10925.757063</td>\n",
              "      <td>13970.619371</td>\n",
              "      <td>29722.736084</td>\n",
              "      <td>21136.560280</td>\n",
              "      <td>...</td>\n",
              "      <td>13858.405874</td>\n",
              "      <td>10263.880000</td>\n",
              "      <td>26530.890559</td>\n",
              "      <td>1328.178252</td>\n",
              "      <td>699.332522</td>\n",
              "      <td>34208.097273</td>\n",
              "      <td>1123.383217</td>\n",
              "      <td>4374.927902</td>\n",
              "      <td>260.886596</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>14789.827343</td>\n",
              "      <td>35729.821748</td>\n",
              "      <td>10683.305105</td>\n",
              "      <td>21089.309301</td>\n",
              "      <td>19838.849231</td>\n",
              "      <td>3395.425455</td>\n",
              "      <td>20268.743776</td>\n",
              "      <td>26438.524336</td>\n",
              "      <td>11792.661678</td>\n",
              "      <td>20666.433776</td>\n",
              "      <td>...</td>\n",
              "      <td>39333.566154</td>\n",
              "      <td>31530.560909</td>\n",
              "      <td>60465.630000</td>\n",
              "      <td>27515.635315</td>\n",
              "      <td>25442.578042</td>\n",
              "      <td>62951.463706</td>\n",
              "      <td>16.986667</td>\n",
              "      <td>16978.366503</td>\n",
              "      <td>6880.466434</td>\n",
              "      <td>298.153714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>11846.558252</td>\n",
              "      <td>24969.477413</td>\n",
              "      <td>7497.356783</td>\n",
              "      <td>17165.947762</td>\n",
              "      <td>19282.746014</td>\n",
              "      <td>2806.416364</td>\n",
              "      <td>13826.694336</td>\n",
              "      <td>21424.470699</td>\n",
              "      <td>13196.569720</td>\n",
              "      <td>12810.480350</td>\n",
              "      <td>...</td>\n",
              "      <td>2981.249510</td>\n",
              "      <td>869.273287</td>\n",
              "      <td>14123.063147</td>\n",
              "      <td>21.240000</td>\n",
              "      <td>599.112568</td>\n",
              "      <td>29575.050769</td>\n",
              "      <td>3596.107762</td>\n",
              "      <td>372.655556</td>\n",
              "      <td>27.930000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>39925.138951</td>\n",
              "      <td>109795.291469</td>\n",
              "      <td>32086.181469</td>\n",
              "      <td>48579.826364</td>\n",
              "      <td>58373.460280</td>\n",
              "      <td>10556.550769</td>\n",
              "      <td>58964.715664</td>\n",
              "      <td>86739.846643</td>\n",
              "      <td>64436.722517</td>\n",
              "      <td>48108.063497</td>\n",
              "      <td>...</td>\n",
              "      <td>14291.869790</td>\n",
              "      <td>12703.554406</td>\n",
              "      <td>50450.731958</td>\n",
              "      <td>1420.418462</td>\n",
              "      <td>393.833168</td>\n",
              "      <td>73344.654685</td>\n",
              "      <td>11079.676643</td>\n",
              "      <td>5323.506503</td>\n",
              "      <td>198.179091</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>18860.911958</td>\n",
              "      <td>57114.326224</td>\n",
              "      <td>17628.778671</td>\n",
              "      <td>28837.744545</td>\n",
              "      <td>36663.363916</td>\n",
              "      <td>5925.281678</td>\n",
              "      <td>34844.108462</td>\n",
              "      <td>34415.449580</td>\n",
              "      <td>19056.162168</td>\n",
              "      <td>23449.992727</td>\n",
              "      <td>...</td>\n",
              "      <td>48995.984196</td>\n",
              "      <td>42030.370699</td>\n",
              "      <td>77392.741608</td>\n",
              "      <td>32623.853706</td>\n",
              "      <td>37474.038531</td>\n",
              "      <td>77487.279091</td>\n",
              "      <td>21685.298811</td>\n",
              "      <td>16596.197552</td>\n",
              "      <td>9570.351469</td>\n",
              "      <td>520.938125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>17330.087622</td>\n",
              "      <td>74494.846224</td>\n",
              "      <td>17535.251678</td>\n",
              "      <td>26673.788182</td>\n",
              "      <td>27756.204615</td>\n",
              "      <td>6741.174895</td>\n",
              "      <td>34242.449161</td>\n",
              "      <td>42229.665035</td>\n",
              "      <td>19553.030490</td>\n",
              "      <td>17975.211119</td>\n",
              "      <td>...</td>\n",
              "      <td>11060.175455</td>\n",
              "      <td>6779.841469</td>\n",
              "      <td>24682.599161</td>\n",
              "      <td>562.897203</td>\n",
              "      <td>355.264000</td>\n",
              "      <td>43405.853357</td>\n",
              "      <td>6.441176</td>\n",
              "      <td>2394.894755</td>\n",
              "      <td>747.609860</td>\n",
              "      <td>29.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>47020.455455</td>\n",
              "      <td>76339.960000</td>\n",
              "      <td>26116.623706</td>\n",
              "      <td>42563.275455</td>\n",
              "      <td>56786.934755</td>\n",
              "      <td>7886.826993</td>\n",
              "      <td>59896.738601</td>\n",
              "      <td>36238.867972</td>\n",
              "      <td>41236.445175</td>\n",
              "      <td>29431.879231</td>\n",
              "      <td>...</td>\n",
              "      <td>115592.108042</td>\n",
              "      <td>81272.990979</td>\n",
              "      <td>162034.099301</td>\n",
              "      <td>50024.937203</td>\n",
              "      <td>75522.874406</td>\n",
              "      <td>136844.834056</td>\n",
              "      <td>9165.079930</td>\n",
              "      <td>27556.759231</td>\n",
              "      <td>14980.825385</td>\n",
              "      <td>732.604651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>30611.783357</td>\n",
              "      <td>77704.857972</td>\n",
              "      <td>19418.273986</td>\n",
              "      <td>52936.323287</td>\n",
              "      <td>33468.325035</td>\n",
              "      <td>7016.829790</td>\n",
              "      <td>53256.150280</td>\n",
              "      <td>53425.359860</td>\n",
              "      <td>22025.603497</td>\n",
              "      <td>20165.667133</td>\n",
              "      <td>...</td>\n",
              "      <td>107174.743986</td>\n",
              "      <td>91406.434615</td>\n",
              "      <td>182527.956014</td>\n",
              "      <td>62088.622937</td>\n",
              "      <td>64541.165664</td>\n",
              "      <td>144446.932517</td>\n",
              "      <td>5.193846</td>\n",
              "      <td>25684.497762</td>\n",
              "      <td>17768.013706</td>\n",
              "      <td>635.556047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>13845.747832</td>\n",
              "      <td>26317.410769</td>\n",
              "      <td>10470.811958</td>\n",
              "      <td>13082.172448</td>\n",
              "      <td>16465.706993</td>\n",
              "      <td>4244.143776</td>\n",
              "      <td>22267.220070</td>\n",
              "      <td>20416.967273</td>\n",
              "      <td>15954.692937</td>\n",
              "      <td>11524.856294</td>\n",
              "      <td>...</td>\n",
              "      <td>5345.240420</td>\n",
              "      <td>3414.740909</td>\n",
              "      <td>18262.376853</td>\n",
              "      <td>422.878252</td>\n",
              "      <td>272.906250</td>\n",
              "      <td>27291.017133</td>\n",
              "      <td>2784.158881</td>\n",
              "      <td>2071.211888</td>\n",
              "      <td>273.504884</td>\n",
              "      <td>29.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>11352.479371</td>\n",
              "      <td>23549.144965</td>\n",
              "      <td>7635.427273</td>\n",
              "      <td>14748.078112</td>\n",
              "      <td>13494.538671</td>\n",
              "      <td>5146.038951</td>\n",
              "      <td>11544.310140</td>\n",
              "      <td>14676.778322</td>\n",
              "      <td>28990.377343</td>\n",
              "      <td>12681.776643</td>\n",
              "      <td>...</td>\n",
              "      <td>6922.744685</td>\n",
              "      <td>3331.204965</td>\n",
              "      <td>20446.967832</td>\n",
              "      <td>997.032281</td>\n",
              "      <td>673.280928</td>\n",
              "      <td>27385.769231</td>\n",
              "      <td>126.934126</td>\n",
              "      <td>2116.696993</td>\n",
              "      <td>42.618571</td>\n",
              "      <td>59.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>22801.609161</td>\n",
              "      <td>42231.844406</td>\n",
              "      <td>19278.955035</td>\n",
              "      <td>23961.357273</td>\n",
              "      <td>27082.325594</td>\n",
              "      <td>5944.435245</td>\n",
              "      <td>19474.770559</td>\n",
              "      <td>20110.270839</td>\n",
              "      <td>27293.658042</td>\n",
              "      <td>14165.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>31293.306224</td>\n",
              "      <td>12033.678951</td>\n",
              "      <td>53043.348741</td>\n",
              "      <td>3646.955664</td>\n",
              "      <td>855.782273</td>\n",
              "      <td>50614.958462</td>\n",
              "      <td>819.416458</td>\n",
              "      <td>7798.283427</td>\n",
              "      <td>169.379120</td>\n",
              "      <td>2.290000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>21988.356224</td>\n",
              "      <td>63665.139510</td>\n",
              "      <td>16392.980490</td>\n",
              "      <td>26775.207203</td>\n",
              "      <td>22933.954965</td>\n",
              "      <td>5664.913077</td>\n",
              "      <td>33152.347203</td>\n",
              "      <td>32036.582098</td>\n",
              "      <td>18589.371259</td>\n",
              "      <td>16754.599860</td>\n",
              "      <td>...</td>\n",
              "      <td>18481.394266</td>\n",
              "      <td>14124.482517</td>\n",
              "      <td>50079.623636</td>\n",
              "      <td>2113.300147</td>\n",
              "      <td>4880.242248</td>\n",
              "      <td>57668.251748</td>\n",
              "      <td>0.481333</td>\n",
              "      <td>5350.500432</td>\n",
              "      <td>881.150853</td>\n",
              "      <td>12.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>21504.029161</td>\n",
              "      <td>50841.072937</td>\n",
              "      <td>18414.224476</td>\n",
              "      <td>31365.545315</td>\n",
              "      <td>28759.223846</td>\n",
              "      <td>5948.962867</td>\n",
              "      <td>33882.926853</td>\n",
              "      <td>42613.662937</td>\n",
              "      <td>30645.018112</td>\n",
              "      <td>27622.457762</td>\n",
              "      <td>...</td>\n",
              "      <td>67545.406434</td>\n",
              "      <td>54692.797413</td>\n",
              "      <td>113720.212937</td>\n",
              "      <td>37087.937063</td>\n",
              "      <td>37643.786434</td>\n",
              "      <td>97240.503566</td>\n",
              "      <td>15860.814825</td>\n",
              "      <td>20370.269720</td>\n",
              "      <td>12884.229091</td>\n",
              "      <td>440.374878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>40545.473217</td>\n",
              "      <td>78251.249930</td>\n",
              "      <td>15490.971259</td>\n",
              "      <td>51456.376643</td>\n",
              "      <td>41647.786503</td>\n",
              "      <td>8210.745734</td>\n",
              "      <td>49394.699231</td>\n",
              "      <td>76445.061259</td>\n",
              "      <td>38243.623916</td>\n",
              "      <td>41826.467552</td>\n",
              "      <td>...</td>\n",
              "      <td>95858.587343</td>\n",
              "      <td>78493.190140</td>\n",
              "      <td>164633.741538</td>\n",
              "      <td>52818.583706</td>\n",
              "      <td>63148.334965</td>\n",
              "      <td>150613.955385</td>\n",
              "      <td>15.266875</td>\n",
              "      <td>25836.062238</td>\n",
              "      <td>19284.377343</td>\n",
              "      <td>796.153864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>14950.049231</td>\n",
              "      <td>47780.599161</td>\n",
              "      <td>14607.126923</td>\n",
              "      <td>19354.728042</td>\n",
              "      <td>16090.874545</td>\n",
              "      <td>3988.656294</td>\n",
              "      <td>24456.825664</td>\n",
              "      <td>18238.059790</td>\n",
              "      <td>16387.963636</td>\n",
              "      <td>14695.978881</td>\n",
              "      <td>...</td>\n",
              "      <td>10983.598741</td>\n",
              "      <td>6735.454126</td>\n",
              "      <td>21915.114965</td>\n",
              "      <td>663.384126</td>\n",
              "      <td>537.663333</td>\n",
              "      <td>40379.295175</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3260.404685</td>\n",
              "      <td>111.680672</td>\n",
              "      <td>29.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>21493.271119</td>\n",
              "      <td>53361.851888</td>\n",
              "      <td>13150.979510</td>\n",
              "      <td>32104.132378</td>\n",
              "      <td>23187.335105</td>\n",
              "      <td>5236.811329</td>\n",
              "      <td>29068.621608</td>\n",
              "      <td>37236.347692</td>\n",
              "      <td>23452.908881</td>\n",
              "      <td>19438.354266</td>\n",
              "      <td>...</td>\n",
              "      <td>21413.411608</td>\n",
              "      <td>21405.250629</td>\n",
              "      <td>51603.339091</td>\n",
              "      <td>2531.663986</td>\n",
              "      <td>857.190894</td>\n",
              "      <td>57868.571119</td>\n",
              "      <td>6.243000</td>\n",
              "      <td>4582.594755</td>\n",
              "      <td>177.560576</td>\n",
              "      <td>27.150000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>33186.460559</td>\n",
              "      <td>70522.580140</td>\n",
              "      <td>19912.564755</td>\n",
              "      <td>27324.303077</td>\n",
              "      <td>36895.869021</td>\n",
              "      <td>7393.499650</td>\n",
              "      <td>43624.067413</td>\n",
              "      <td>36710.240909</td>\n",
              "      <td>50178.361748</td>\n",
              "      <td>31155.170559</td>\n",
              "      <td>...</td>\n",
              "      <td>20814.992168</td>\n",
              "      <td>19604.867692</td>\n",
              "      <td>59604.574615</td>\n",
              "      <td>2111.610780</td>\n",
              "      <td>374.898804</td>\n",
              "      <td>54199.088322</td>\n",
              "      <td>13168.146713</td>\n",
              "      <td>6149.684755</td>\n",
              "      <td>100.585083</td>\n",
              "      <td>29.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>18859.023357</td>\n",
              "      <td>40797.169301</td>\n",
              "      <td>11825.589021</td>\n",
              "      <td>29245.357552</td>\n",
              "      <td>29178.058811</td>\n",
              "      <td>4911.185804</td>\n",
              "      <td>28788.329441</td>\n",
              "      <td>49171.841748</td>\n",
              "      <td>23246.748322</td>\n",
              "      <td>27175.089231</td>\n",
              "      <td>...</td>\n",
              "      <td>72650.442867</td>\n",
              "      <td>52435.498252</td>\n",
              "      <td>121882.073916</td>\n",
              "      <td>37876.836853</td>\n",
              "      <td>51850.045105</td>\n",
              "      <td>93927.992098</td>\n",
              "      <td>13623.074615</td>\n",
              "      <td>18597.824126</td>\n",
              "      <td>9878.970140</td>\n",
              "      <td>413.774211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>20145.897483</td>\n",
              "      <td>36871.310559</td>\n",
              "      <td>11788.130979</td>\n",
              "      <td>20351.455455</td>\n",
              "      <td>12422.996434</td>\n",
              "      <td>3760.045035</td>\n",
              "      <td>17971.439580</td>\n",
              "      <td>29858.353636</td>\n",
              "      <td>14636.113636</td>\n",
              "      <td>20202.701469</td>\n",
              "      <td>...</td>\n",
              "      <td>11932.596503</td>\n",
              "      <td>7767.272098</td>\n",
              "      <td>38854.460699</td>\n",
              "      <td>777.747483</td>\n",
              "      <td>2607.109754</td>\n",
              "      <td>43991.147692</td>\n",
              "      <td>-1.270000</td>\n",
              "      <td>2706.628252</td>\n",
              "      <td>665.919779</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>19402.762937</td>\n",
              "      <td>27398.030979</td>\n",
              "      <td>7357.400769</td>\n",
              "      <td>24498.113846</td>\n",
              "      <td>17589.532587</td>\n",
              "      <td>4656.670490</td>\n",
              "      <td>16287.658531</td>\n",
              "      <td>28694.950909</td>\n",
              "      <td>16556.330769</td>\n",
              "      <td>10172.815734</td>\n",
              "      <td>...</td>\n",
              "      <td>57016.589231</td>\n",
              "      <td>39434.281259</td>\n",
              "      <td>84988.311818</td>\n",
              "      <td>25615.331469</td>\n",
              "      <td>42544.202028</td>\n",
              "      <td>70236.827622</td>\n",
              "      <td>18596.331888</td>\n",
              "      <td>14830.084825</td>\n",
              "      <td>8025.948601</td>\n",
              "      <td>221.950278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>30437.976224</td>\n",
              "      <td>79001.049161</td>\n",
              "      <td>20226.734615</td>\n",
              "      <td>43596.933916</td>\n",
              "      <td>28059.038252</td>\n",
              "      <td>7730.729091</td>\n",
              "      <td>43272.914965</td>\n",
              "      <td>42181.469580</td>\n",
              "      <td>29315.697133</td>\n",
              "      <td>36757.327413</td>\n",
              "      <td>...</td>\n",
              "      <td>96374.536573</td>\n",
              "      <td>66687.096573</td>\n",
              "      <td>146518.141399</td>\n",
              "      <td>54910.693776</td>\n",
              "      <td>69638.930420</td>\n",
              "      <td>119519.410909</td>\n",
              "      <td>20806.990909</td>\n",
              "      <td>21268.805734</td>\n",
              "      <td>11524.137832</td>\n",
              "      <td>562.980000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>20180.453986</td>\n",
              "      <td>57751.274336</td>\n",
              "      <td>12562.223287</td>\n",
              "      <td>27980.817203</td>\n",
              "      <td>28221.618392</td>\n",
              "      <td>5016.258671</td>\n",
              "      <td>29228.446923</td>\n",
              "      <td>33375.575524</td>\n",
              "      <td>17930.710070</td>\n",
              "      <td>21083.404825</td>\n",
              "      <td>...</td>\n",
              "      <td>65285.952098</td>\n",
              "      <td>57575.601119</td>\n",
              "      <td>98486.960350</td>\n",
              "      <td>47923.508671</td>\n",
              "      <td>36164.364615</td>\n",
              "      <td>96322.113846</td>\n",
              "      <td>26288.955734</td>\n",
              "      <td>23828.861329</td>\n",
              "      <td>10673.133077</td>\n",
              "      <td>316.605610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>15504.699580</td>\n",
              "      <td>25181.662727</td>\n",
              "      <td>7995.955804</td>\n",
              "      <td>14326.216224</td>\n",
              "      <td>12931.821259</td>\n",
              "      <td>3289.884965</td>\n",
              "      <td>16854.082238</td>\n",
              "      <td>20680.465944</td>\n",
              "      <td>11370.866364</td>\n",
              "      <td>9400.183077</td>\n",
              "      <td>...</td>\n",
              "      <td>10950.327972</td>\n",
              "      <td>4691.213217</td>\n",
              "      <td>25166.714266</td>\n",
              "      <td>1190.882098</td>\n",
              "      <td>263.083012</td>\n",
              "      <td>30980.395594</td>\n",
              "      <td>11.800000</td>\n",
              "      <td>2131.676783</td>\n",
              "      <td>139.677971</td>\n",
              "      <td>29.880000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>9788.376643</td>\n",
              "      <td>12974.464476</td>\n",
              "      <td>739.981888</td>\n",
              "      <td>13216.100909</td>\n",
              "      <td>405.565944</td>\n",
              "      <td>27.303937</td>\n",
              "      <td>379.771958</td>\n",
              "      <td>11733.993776</td>\n",
              "      <td>76.845352</td>\n",
              "      <td>196.116923</td>\n",
              "      <td>...</td>\n",
              "      <td>34622.986224</td>\n",
              "      <td>31576.583986</td>\n",
              "      <td>53256.041399</td>\n",
              "      <td>22409.698392</td>\n",
              "      <td>24522.622587</td>\n",
              "      <td>45456.508322</td>\n",
              "      <td>19163.112028</td>\n",
              "      <td>13172.531119</td>\n",
              "      <td>3207.034685</td>\n",
              "      <td>-0.641818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>17356.652448</td>\n",
              "      <td>58512.131538</td>\n",
              "      <td>10616.675944</td>\n",
              "      <td>34848.899231</td>\n",
              "      <td>18715.630769</td>\n",
              "      <td>3489.809441</td>\n",
              "      <td>21012.438531</td>\n",
              "      <td>25277.976713</td>\n",
              "      <td>10815.516713</td>\n",
              "      <td>19911.584406</td>\n",
              "      <td>...</td>\n",
              "      <td>86167.265804</td>\n",
              "      <td>70232.133566</td>\n",
              "      <td>127010.118601</td>\n",
              "      <td>57876.205664</td>\n",
              "      <td>68732.141818</td>\n",
              "      <td>106696.019231</td>\n",
              "      <td>30335.294266</td>\n",
              "      <td>31144.978112</td>\n",
              "      <td>10101.886713</td>\n",
              "      <td>218.742203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>22852.639510</td>\n",
              "      <td>50323.497343</td>\n",
              "      <td>15472.540140</td>\n",
              "      <td>28137.154965</td>\n",
              "      <td>20748.371888</td>\n",
              "      <td>4589.748392</td>\n",
              "      <td>25375.036993</td>\n",
              "      <td>24681.349580</td>\n",
              "      <td>20739.684685</td>\n",
              "      <td>22887.257483</td>\n",
              "      <td>...</td>\n",
              "      <td>61639.637133</td>\n",
              "      <td>48368.756154</td>\n",
              "      <td>100122.929021</td>\n",
              "      <td>30732.226923</td>\n",
              "      <td>48650.040979</td>\n",
              "      <td>84695.234196</td>\n",
              "      <td>2308.411818</td>\n",
              "      <td>17160.310000</td>\n",
              "      <td>7939.262378</td>\n",
              "      <td>379.147250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2379.086573</td>\n",
              "      <td>7471.425105</td>\n",
              "      <td>283.950140</td>\n",
              "      <td>6107.616014</td>\n",
              "      <td>112.728310</td>\n",
              "      <td>11.996538</td>\n",
              "      <td>392.912867</td>\n",
              "      <td>3679.792168</td>\n",
              "      <td>42.788348</td>\n",
              "      <td>80.301189</td>\n",
              "      <td>...</td>\n",
              "      <td>24899.923147</td>\n",
              "      <td>9862.862867</td>\n",
              "      <td>34227.662867</td>\n",
              "      <td>25648.054266</td>\n",
              "      <td>29002.624476</td>\n",
              "      <td>27022.949161</td>\n",
              "      <td>9371.822168</td>\n",
              "      <td>5375.769510</td>\n",
              "      <td>7340.692168</td>\n",
              "      <td>0.022000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>19947.573077</td>\n",
              "      <td>34916.225874</td>\n",
              "      <td>8377.376434</td>\n",
              "      <td>19791.509021</td>\n",
              "      <td>21633.900559</td>\n",
              "      <td>3419.062028</td>\n",
              "      <td>18055.491608</td>\n",
              "      <td>27165.013147</td>\n",
              "      <td>17224.253497</td>\n",
              "      <td>16957.163566</td>\n",
              "      <td>...</td>\n",
              "      <td>44338.936783</td>\n",
              "      <td>34018.102238</td>\n",
              "      <td>67782.520909</td>\n",
              "      <td>29590.111329</td>\n",
              "      <td>37428.096923</td>\n",
              "      <td>69245.187972</td>\n",
              "      <td>19154.212308</td>\n",
              "      <td>17570.577483</td>\n",
              "      <td>7775.998182</td>\n",
              "      <td>347.144324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>17082.647902</td>\n",
              "      <td>45578.456224</td>\n",
              "      <td>14308.382797</td>\n",
              "      <td>19495.631119</td>\n",
              "      <td>24858.433706</td>\n",
              "      <td>7256.417133</td>\n",
              "      <td>30267.589790</td>\n",
              "      <td>18416.401678</td>\n",
              "      <td>15657.032937</td>\n",
              "      <td>14818.443706</td>\n",
              "      <td>...</td>\n",
              "      <td>12960.450210</td>\n",
              "      <td>7919.080140</td>\n",
              "      <td>33776.032028</td>\n",
              "      <td>1528.451469</td>\n",
              "      <td>200.270435</td>\n",
              "      <td>43286.536993</td>\n",
              "      <td>10.788333</td>\n",
              "      <td>3738.292517</td>\n",
              "      <td>68.284831</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2239.227413</td>\n",
              "      <td>13416.025664</td>\n",
              "      <td>381.324266</td>\n",
              "      <td>9873.505105</td>\n",
              "      <td>314.753982</td>\n",
              "      <td>26.291579</td>\n",
              "      <td>414.428322</td>\n",
              "      <td>3417.640420</td>\n",
              "      <td>102.211739</td>\n",
              "      <td>175.052308</td>\n",
              "      <td>...</td>\n",
              "      <td>35474.191958</td>\n",
              "      <td>11097.875874</td>\n",
              "      <td>44539.564476</td>\n",
              "      <td>26103.315664</td>\n",
              "      <td>47372.151119</td>\n",
              "      <td>39735.688741</td>\n",
              "      <td>15683.341818</td>\n",
              "      <td>6469.273636</td>\n",
              "      <td>9009.943776</td>\n",
              "      <td>0.020000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>11024.235874</td>\n",
              "      <td>16511.446224</td>\n",
              "      <td>1297.862028</td>\n",
              "      <td>17614.013636</td>\n",
              "      <td>1137.631189</td>\n",
              "      <td>46.313630</td>\n",
              "      <td>824.978392</td>\n",
              "      <td>16151.397902</td>\n",
              "      <td>151.233803</td>\n",
              "      <td>387.644685</td>\n",
              "      <td>...</td>\n",
              "      <td>44144.428112</td>\n",
              "      <td>30870.677063</td>\n",
              "      <td>59440.577133</td>\n",
              "      <td>21599.851049</td>\n",
              "      <td>33656.648112</td>\n",
              "      <td>51410.551119</td>\n",
              "      <td>20375.380769</td>\n",
              "      <td>13960.701399</td>\n",
              "      <td>5286.761119</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>6923.538531</td>\n",
              "      <td>10986.172657</td>\n",
              "      <td>498.700210</td>\n",
              "      <td>10669.501329</td>\n",
              "      <td>397.418322</td>\n",
              "      <td>37.014855</td>\n",
              "      <td>413.539021</td>\n",
              "      <td>9485.399441</td>\n",
              "      <td>77.520350</td>\n",
              "      <td>365.364895</td>\n",
              "      <td>...</td>\n",
              "      <td>34765.576783</td>\n",
              "      <td>25404.860420</td>\n",
              "      <td>45314.434825</td>\n",
              "      <td>18868.919091</td>\n",
              "      <td>21331.411259</td>\n",
              "      <td>41793.649021</td>\n",
              "      <td>11981.676643</td>\n",
              "      <td>9902.368182</td>\n",
              "      <td>4783.086713</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>21925.021189</td>\n",
              "      <td>67338.429371</td>\n",
              "      <td>20569.701608</td>\n",
              "      <td>44807.515105</td>\n",
              "      <td>24043.436783</td>\n",
              "      <td>4911.540420</td>\n",
              "      <td>40020.492867</td>\n",
              "      <td>36130.641608</td>\n",
              "      <td>19396.117692</td>\n",
              "      <td>14919.373916</td>\n",
              "      <td>...</td>\n",
              "      <td>78649.534685</td>\n",
              "      <td>60386.286014</td>\n",
              "      <td>110126.209580</td>\n",
              "      <td>39684.510000</td>\n",
              "      <td>59830.190280</td>\n",
              "      <td>103036.757133</td>\n",
              "      <td>27089.158601</td>\n",
              "      <td>23993.406853</td>\n",
              "      <td>9767.295734</td>\n",
              "      <td>334.869756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>18794.578811</td>\n",
              "      <td>26702.705175</td>\n",
              "      <td>6489.030350</td>\n",
              "      <td>24386.750559</td>\n",
              "      <td>17689.671678</td>\n",
              "      <td>4003.068601</td>\n",
              "      <td>18898.214336</td>\n",
              "      <td>33971.532238</td>\n",
              "      <td>19065.436294</td>\n",
              "      <td>19612.629301</td>\n",
              "      <td>...</td>\n",
              "      <td>61258.202867</td>\n",
              "      <td>43256.156853</td>\n",
              "      <td>96475.753287</td>\n",
              "      <td>27532.751189</td>\n",
              "      <td>38210.900699</td>\n",
              "      <td>66572.881259</td>\n",
              "      <td>15309.077972</td>\n",
              "      <td>17131.033497</td>\n",
              "      <td>8178.371049</td>\n",
              "      <td>167.374167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>23205.259930</td>\n",
              "      <td>48349.828951</td>\n",
              "      <td>17021.833357</td>\n",
              "      <td>30538.574895</td>\n",
              "      <td>25513.943776</td>\n",
              "      <td>5267.832098</td>\n",
              "      <td>33711.105734</td>\n",
              "      <td>33729.081678</td>\n",
              "      <td>32743.470140</td>\n",
              "      <td>15194.223706</td>\n",
              "      <td>...</td>\n",
              "      <td>70852.021818</td>\n",
              "      <td>52714.928462</td>\n",
              "      <td>115827.664056</td>\n",
              "      <td>35415.340000</td>\n",
              "      <td>47218.529161</td>\n",
              "      <td>88666.468392</td>\n",
              "      <td>2883.492238</td>\n",
              "      <td>19789.219231</td>\n",
              "      <td>9371.531608</td>\n",
              "      <td>443.736512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>10375.148392</td>\n",
              "      <td>15976.902448</td>\n",
              "      <td>814.451189</td>\n",
              "      <td>14885.264755</td>\n",
              "      <td>1052.296783</td>\n",
              "      <td>3.333333</td>\n",
              "      <td>721.913846</td>\n",
              "      <td>18238.584196</td>\n",
              "      <td>135.524056</td>\n",
              "      <td>404.596014</td>\n",
              "      <td>...</td>\n",
              "      <td>53384.897902</td>\n",
              "      <td>42913.221259</td>\n",
              "      <td>83497.778671</td>\n",
              "      <td>32852.632308</td>\n",
              "      <td>35724.612098</td>\n",
              "      <td>61205.272308</td>\n",
              "      <td>15183.474196</td>\n",
              "      <td>17495.198811</td>\n",
              "      <td>6540.721259</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>7549.109021</td>\n",
              "      <td>20722.851469</td>\n",
              "      <td>999.648881</td>\n",
              "      <td>18227.382168</td>\n",
              "      <td>575.417326</td>\n",
              "      <td>37.843246</td>\n",
              "      <td>516.772867</td>\n",
              "      <td>13185.211678</td>\n",
              "      <td>147.694196</td>\n",
              "      <td>507.426713</td>\n",
              "      <td>...</td>\n",
              "      <td>63668.895594</td>\n",
              "      <td>34808.442168</td>\n",
              "      <td>83646.160909</td>\n",
              "      <td>36196.693217</td>\n",
              "      <td>50769.708322</td>\n",
              "      <td>72883.223287</td>\n",
              "      <td>25058.369371</td>\n",
              "      <td>19349.989930</td>\n",
              "      <td>9594.867483</td>\n",
              "      <td>26.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>8049.992308</td>\n",
              "      <td>9377.273007</td>\n",
              "      <td>571.016713</td>\n",
              "      <td>7403.959580</td>\n",
              "      <td>960.670490</td>\n",
              "      <td>34.648722</td>\n",
              "      <td>531.034895</td>\n",
              "      <td>4963.966224</td>\n",
              "      <td>99.817273</td>\n",
              "      <td>153.792657</td>\n",
              "      <td>...</td>\n",
              "      <td>31182.601818</td>\n",
              "      <td>18169.510070</td>\n",
              "      <td>39619.563287</td>\n",
              "      <td>11029.915734</td>\n",
              "      <td>23812.046993</td>\n",
              "      <td>31100.185175</td>\n",
              "      <td>2834.139580</td>\n",
              "      <td>6636.467413</td>\n",
              "      <td>3466.077063</td>\n",
              "      <td>3.505000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>17745.916014</td>\n",
              "      <td>35800.912448</td>\n",
              "      <td>9508.014965</td>\n",
              "      <td>24229.873147</td>\n",
              "      <td>16107.063077</td>\n",
              "      <td>3554.222657</td>\n",
              "      <td>23757.771538</td>\n",
              "      <td>34050.409580</td>\n",
              "      <td>15485.885804</td>\n",
              "      <td>14245.086993</td>\n",
              "      <td>...</td>\n",
              "      <td>23674.035245</td>\n",
              "      <td>16641.927343</td>\n",
              "      <td>48125.897762</td>\n",
              "      <td>2728.627133</td>\n",
              "      <td>3690.272090</td>\n",
              "      <td>52896.166643</td>\n",
              "      <td>2.970000</td>\n",
              "      <td>6466.961888</td>\n",
              "      <td>561.239037</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45 rows × 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa2b65bf-ff00-476e-a4b4-d74cb352327c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aa2b65bf-ff00-476e-a4b4-d74cb352327c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aa2b65bf-ff00-476e-a4b4-d74cb352327c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[data['Weekly_Sales']<=0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "id": "oPMJ1Npq0r17",
        "outputId": "dc0cdad0-5d4d-4e2a-8d06-7e911a422ae1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Unnamed: 0  Store       Date  IsHoliday  Dept  Weekly_Sales  \\\n",
              "182            182      1 2010-02-19          0  47.0       -863.00   \n",
              "429            429      1 2010-03-12          0  47.0       -698.00   \n",
              "2555          2555      1 2010-10-08          0  47.0        -58.00   \n",
              "3632          3632      1 2011-01-21          0  54.0        -50.00   \n",
              "4109          4109      1 2011-03-11          0  47.0          0.00   \n",
              "...            ...    ...        ...        ...   ...           ...   \n",
              "420031      421747     45 2012-05-25          0  49.0         -4.97   \n",
              "420370      422086     45 2012-06-29          0  49.0        -34.00   \n",
              "420736      422452     45 2012-08-03          0  49.0         -1.91   \n",
              "421016      422732     45 2012-08-31          0  54.0          0.00   \n",
              "421131      422847     45 2012-09-14          0  49.0         -6.83   \n",
              "\n",
              "        Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  MarkDown4  \\\n",
              "182           39.93       2.514       0.00       0.00       0.00       0.00   \n",
              "429           57.79       2.667       0.00       0.00       0.00       0.00   \n",
              "2555          63.93       2.633       0.00       0.00       0.00       0.00   \n",
              "3632          44.04       3.016       0.00       0.00       0.00       0.00   \n",
              "4109          53.56       3.459       0.00       0.00       0.00       0.00   \n",
              "...             ...         ...        ...        ...        ...        ...   \n",
              "420031        67.21       3.798    5370.39       0.00     361.22    1287.62   \n",
              "420370        75.22       3.506    3291.36     425.60       0.00     314.88   \n",
              "420736        76.58       3.654   24853.05      39.56      17.96   11142.69   \n",
              "421016        75.09       3.867   23641.30       6.00      92.93    6988.31   \n",
              "421131        67.87       3.948   11407.95       0.00       4.30    3421.72   \n",
              "\n",
              "        MarkDown5         CPI  Unemployment  Type    Size  \n",
              "182          0.00  211.289143         8.106     3  151315  \n",
              "429          0.00  211.380643         8.106     3  151315  \n",
              "2555         0.00  211.746754         7.838     3  151315  \n",
              "3632         0.00  211.827234         7.742     3  151315  \n",
              "4109         0.00  214.111056         7.742     3  151315  \n",
              "...           ...         ...           ...   ...     ...  \n",
              "420031    2461.81  191.002810         8.567     2  118221  \n",
              "420370    2255.34  191.099246         8.567     2  118221  \n",
              "420736    2768.32  191.164090         8.684     2  118221  \n",
              "421016    3992.13  191.461281         8.684     2  118221  \n",
              "421131    5268.92  191.699850         8.684     2  118221  \n",
              "\n",
              "[1358 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86a51a8f-0717-43dc-a029-9f42b15017ce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Store</th>\n",
              "      <th>Date</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>Type</th>\n",
              "      <th>Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>182</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-02-19</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>-863.00</td>\n",
              "      <td>39.93</td>\n",
              "      <td>2.514</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>211.289143</td>\n",
              "      <td>8.106</td>\n",
              "      <td>3</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>429</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-03-12</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>-698.00</td>\n",
              "      <td>57.79</td>\n",
              "      <td>2.667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>211.380643</td>\n",
              "      <td>8.106</td>\n",
              "      <td>3</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2555</th>\n",
              "      <td>2555</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-10-08</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>-58.00</td>\n",
              "      <td>63.93</td>\n",
              "      <td>2.633</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>211.746754</td>\n",
              "      <td>7.838</td>\n",
              "      <td>3</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3632</th>\n",
              "      <td>3632</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-01-21</td>\n",
              "      <td>0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>-50.00</td>\n",
              "      <td>44.04</td>\n",
              "      <td>3.016</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>211.827234</td>\n",
              "      <td>7.742</td>\n",
              "      <td>3</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4109</th>\n",
              "      <td>4109</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-03-11</td>\n",
              "      <td>0</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>53.56</td>\n",
              "      <td>3.459</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>214.111056</td>\n",
              "      <td>7.742</td>\n",
              "      <td>3</td>\n",
              "      <td>151315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420031</th>\n",
              "      <td>421747</td>\n",
              "      <td>45</td>\n",
              "      <td>2012-05-25</td>\n",
              "      <td>0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>-4.97</td>\n",
              "      <td>67.21</td>\n",
              "      <td>3.798</td>\n",
              "      <td>5370.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>361.22</td>\n",
              "      <td>1287.62</td>\n",
              "      <td>2461.81</td>\n",
              "      <td>191.002810</td>\n",
              "      <td>8.567</td>\n",
              "      <td>2</td>\n",
              "      <td>118221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420370</th>\n",
              "      <td>422086</td>\n",
              "      <td>45</td>\n",
              "      <td>2012-06-29</td>\n",
              "      <td>0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>-34.00</td>\n",
              "      <td>75.22</td>\n",
              "      <td>3.506</td>\n",
              "      <td>3291.36</td>\n",
              "      <td>425.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>314.88</td>\n",
              "      <td>2255.34</td>\n",
              "      <td>191.099246</td>\n",
              "      <td>8.567</td>\n",
              "      <td>2</td>\n",
              "      <td>118221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420736</th>\n",
              "      <td>422452</td>\n",
              "      <td>45</td>\n",
              "      <td>2012-08-03</td>\n",
              "      <td>0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>-1.91</td>\n",
              "      <td>76.58</td>\n",
              "      <td>3.654</td>\n",
              "      <td>24853.05</td>\n",
              "      <td>39.56</td>\n",
              "      <td>17.96</td>\n",
              "      <td>11142.69</td>\n",
              "      <td>2768.32</td>\n",
              "      <td>191.164090</td>\n",
              "      <td>8.684</td>\n",
              "      <td>2</td>\n",
              "      <td>118221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421016</th>\n",
              "      <td>422732</td>\n",
              "      <td>45</td>\n",
              "      <td>2012-08-31</td>\n",
              "      <td>0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>75.09</td>\n",
              "      <td>3.867</td>\n",
              "      <td>23641.30</td>\n",
              "      <td>6.00</td>\n",
              "      <td>92.93</td>\n",
              "      <td>6988.31</td>\n",
              "      <td>3992.13</td>\n",
              "      <td>191.461281</td>\n",
              "      <td>8.684</td>\n",
              "      <td>2</td>\n",
              "      <td>118221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421131</th>\n",
              "      <td>422847</td>\n",
              "      <td>45</td>\n",
              "      <td>2012-09-14</td>\n",
              "      <td>0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>-6.83</td>\n",
              "      <td>67.87</td>\n",
              "      <td>3.948</td>\n",
              "      <td>11407.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.30</td>\n",
              "      <td>3421.72</td>\n",
              "      <td>5268.92</td>\n",
              "      <td>191.699850</td>\n",
              "      <td>8.684</td>\n",
              "      <td>2</td>\n",
              "      <td>118221</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1358 rows × 17 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86a51a8f-0717-43dc-a029-9f42b15017ce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86a51a8f-0717-43dc-a029-9f42b15017ce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86a51a8f-0717-43dc-a029-9f42b15017ce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = data.loc[data['Weekly_Sales'] > 0]\n"
      ],
      "metadata": {
        "id": "c91NgOvf0vsi"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2['Date'].head(5).append(data2['Date'].tail(5)) # to see first and last 5 rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC2XbzsW0yWB",
        "outputId": "ecb62bf9-be8e-48be-8365-8ab77063a16d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        2010-02-05\n",
              "1        2010-02-05\n",
              "2        2010-02-05\n",
              "3        2010-02-05\n",
              "4        2010-02-05\n",
              "421565   2012-10-26\n",
              "421566   2012-10-26\n",
              "421567   2012-10-26\n",
              "421568   2012-10-26\n",
              "421569   2012-10-26\n",
              "Name: Date, dtype: datetime64[ns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.barplot(x='IsHoliday', y='Weekly_Sales', data=data2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "ml5KDhoH007e",
        "outputId": "0f913550-f623-48b7-dd04-94ddb832ed98"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f91e5d2d9d0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df= data2.copy()"
      ],
      "metadata": {
        "id": "inKPxCgb1B3N"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.set_index('Date', inplace=True)"
      ],
      "metadata": {
        "id": "j8utcbq41EkB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.resample('W-MON').sum()\n",
        "#df.resample('W-MON')\n",
        "#.interpolate()[::7]"
      ],
      "metadata": {
        "id": "cntPnXsP1uSI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "7MyocPqV1xkI",
        "outputId": "d9ebd24f-4622-49b7-e282-bfc26b1071f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Unnamed: 0  Store  IsHoliday      Dept  Weekly_Sales  Temperature  \\\n",
              "Date                                                                            \n",
              "2010-02-08   604946596  64931          0  130099.0   49750875.98     98051.13   \n",
              "2010-02-15   604785266  64897       2949  130734.0   48336800.10     98409.44   \n",
              "2010-02-22   610391383  65472          0  131534.0   48277902.33    109986.81   \n",
              "2010-03-01   603712495  64742          0  129533.0   43970440.65    113556.93   \n",
              "2010-03-08   604069157  64757          0  129242.0   46872715.16    124390.95   \n",
              "...                ...    ...        ...       ...           ...          ...   \n",
              "2012-10-01   638518858  65617          0  130183.0   43735713.56    201219.39   \n",
              "2012-10-08   642393763  65995          0  132042.0   47567053.49    194107.46   \n",
              "2012-10-15   644098516  66145          0  132786.0   46128909.98    171823.03   \n",
              "2012-10-22   638904376  65597          0  130046.0   45122443.96    177256.57   \n",
              "2012-10-29   640065453  65702          0  130242.0   45544379.53    178637.12   \n",
              "\n",
              "            Fuel_Price    MarkDown1  MarkDown2  MarkDown3   MarkDown4  \\\n",
              "Date                                                                    \n",
              "2010-02-08    8007.134         0.00       0.00       0.00        0.00   \n",
              "2010-02-15    7950.372         0.00       0.00       0.00        0.00   \n",
              "2010-02-22    7940.313         0.00       0.00       0.00        0.00   \n",
              "2010-03-01    7895.330         0.00       0.00       0.00        0.00   \n",
              "2010-03-08    8020.926         0.00       0.00       0.00        0.00   \n",
              "...                ...          ...        ...        ...         ...   \n",
              "2012-10-01   11388.865  14451609.34   56298.54   15491.09  5020072.96   \n",
              "2012-10-08   11414.187  14962702.47       0.00   59307.01  8336451.60   \n",
              "2012-10-15   11609.130   5827442.08       0.00   49975.57  1659507.32   \n",
              "2012-10-22   11429.274   5649154.50       0.00   38903.96  1273331.14   \n",
              "2012-10-29   11186.591  14564265.92  203048.00  194299.16  1868266.88   \n",
              "\n",
              "              MarkDown5            CPI  Unemployment  Type       Size  \n",
              "Date                                                                   \n",
              "2010-02-08         0.00  492949.905535     25272.533  7106  404726444  \n",
              "2010-02-15         0.00  493668.382611     25266.603  7122  406003811  \n",
              "2010-02-22         0.00  497137.036639     25466.540  7164  407715096  \n",
              "2010-03-01         0.00  493062.204817     25172.556  7092  403855974  \n",
              "2010-03-08         0.00  492308.584801     25172.941  7088  403865218  \n",
              "...                 ...            ...           ...   ...        ...  \n",
              "2012-10-01  12536021.25  519503.517745     21320.389  7099  401708549  \n",
              "2012-10-08  10745961.80  522037.213368     20586.126  7145  404910680  \n",
              "2012-10-15  16708284.32  524784.698226     20701.180  7169  405992240  \n",
              "2012-10-22   9746489.22  519574.770121     20474.862  7074  400612840  \n",
              "2012-10-29   5587308.08  520062.606140     20485.820  7091  401698653  \n",
              "\n",
              "[143 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc42ea52-4518-47f6-a7df-b32284565fe1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Store</th>\n",
              "      <th>IsHoliday</th>\n",
              "      <th>Dept</th>\n",
              "      <th>Weekly_Sales</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Fuel_Price</th>\n",
              "      <th>MarkDown1</th>\n",
              "      <th>MarkDown2</th>\n",
              "      <th>MarkDown3</th>\n",
              "      <th>MarkDown4</th>\n",
              "      <th>MarkDown5</th>\n",
              "      <th>CPI</th>\n",
              "      <th>Unemployment</th>\n",
              "      <th>Type</th>\n",
              "      <th>Size</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-02-08</th>\n",
              "      <td>604946596</td>\n",
              "      <td>64931</td>\n",
              "      <td>0</td>\n",
              "      <td>130099.0</td>\n",
              "      <td>49750875.98</td>\n",
              "      <td>98051.13</td>\n",
              "      <td>8007.134</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>492949.905535</td>\n",
              "      <td>25272.533</td>\n",
              "      <td>7106</td>\n",
              "      <td>404726444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-15</th>\n",
              "      <td>604785266</td>\n",
              "      <td>64897</td>\n",
              "      <td>2949</td>\n",
              "      <td>130734.0</td>\n",
              "      <td>48336800.10</td>\n",
              "      <td>98409.44</td>\n",
              "      <td>7950.372</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>493668.382611</td>\n",
              "      <td>25266.603</td>\n",
              "      <td>7122</td>\n",
              "      <td>406003811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-22</th>\n",
              "      <td>610391383</td>\n",
              "      <td>65472</td>\n",
              "      <td>0</td>\n",
              "      <td>131534.0</td>\n",
              "      <td>48277902.33</td>\n",
              "      <td>109986.81</td>\n",
              "      <td>7940.313</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>497137.036639</td>\n",
              "      <td>25466.540</td>\n",
              "      <td>7164</td>\n",
              "      <td>407715096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-01</th>\n",
              "      <td>603712495</td>\n",
              "      <td>64742</td>\n",
              "      <td>0</td>\n",
              "      <td>129533.0</td>\n",
              "      <td>43970440.65</td>\n",
              "      <td>113556.93</td>\n",
              "      <td>7895.330</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>493062.204817</td>\n",
              "      <td>25172.556</td>\n",
              "      <td>7092</td>\n",
              "      <td>403855974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-08</th>\n",
              "      <td>604069157</td>\n",
              "      <td>64757</td>\n",
              "      <td>0</td>\n",
              "      <td>129242.0</td>\n",
              "      <td>46872715.16</td>\n",
              "      <td>124390.95</td>\n",
              "      <td>8020.926</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>492308.584801</td>\n",
              "      <td>25172.941</td>\n",
              "      <td>7088</td>\n",
              "      <td>403865218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-01</th>\n",
              "      <td>638518858</td>\n",
              "      <td>65617</td>\n",
              "      <td>0</td>\n",
              "      <td>130183.0</td>\n",
              "      <td>43735713.56</td>\n",
              "      <td>201219.39</td>\n",
              "      <td>11388.865</td>\n",
              "      <td>14451609.34</td>\n",
              "      <td>56298.54</td>\n",
              "      <td>15491.09</td>\n",
              "      <td>5020072.96</td>\n",
              "      <td>12536021.25</td>\n",
              "      <td>519503.517745</td>\n",
              "      <td>21320.389</td>\n",
              "      <td>7099</td>\n",
              "      <td>401708549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-08</th>\n",
              "      <td>642393763</td>\n",
              "      <td>65995</td>\n",
              "      <td>0</td>\n",
              "      <td>132042.0</td>\n",
              "      <td>47567053.49</td>\n",
              "      <td>194107.46</td>\n",
              "      <td>11414.187</td>\n",
              "      <td>14962702.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>59307.01</td>\n",
              "      <td>8336451.60</td>\n",
              "      <td>10745961.80</td>\n",
              "      <td>522037.213368</td>\n",
              "      <td>20586.126</td>\n",
              "      <td>7145</td>\n",
              "      <td>404910680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-15</th>\n",
              "      <td>644098516</td>\n",
              "      <td>66145</td>\n",
              "      <td>0</td>\n",
              "      <td>132786.0</td>\n",
              "      <td>46128909.98</td>\n",
              "      <td>171823.03</td>\n",
              "      <td>11609.130</td>\n",
              "      <td>5827442.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>49975.57</td>\n",
              "      <td>1659507.32</td>\n",
              "      <td>16708284.32</td>\n",
              "      <td>524784.698226</td>\n",
              "      <td>20701.180</td>\n",
              "      <td>7169</td>\n",
              "      <td>405992240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-22</th>\n",
              "      <td>638904376</td>\n",
              "      <td>65597</td>\n",
              "      <td>0</td>\n",
              "      <td>130046.0</td>\n",
              "      <td>45122443.96</td>\n",
              "      <td>177256.57</td>\n",
              "      <td>11429.274</td>\n",
              "      <td>5649154.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>38903.96</td>\n",
              "      <td>1273331.14</td>\n",
              "      <td>9746489.22</td>\n",
              "      <td>519574.770121</td>\n",
              "      <td>20474.862</td>\n",
              "      <td>7074</td>\n",
              "      <td>400612840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012-10-29</th>\n",
              "      <td>640065453</td>\n",
              "      <td>65702</td>\n",
              "      <td>0</td>\n",
              "      <td>130242.0</td>\n",
              "      <td>45544379.53</td>\n",
              "      <td>178637.12</td>\n",
              "      <td>11186.591</td>\n",
              "      <td>14564265.92</td>\n",
              "      <td>203048.00</td>\n",
              "      <td>194299.16</td>\n",
              "      <td>1868266.88</td>\n",
              "      <td>5587308.08</td>\n",
              "      <td>520062.606140</td>\n",
              "      <td>20485.820</td>\n",
              "      <td>7091</td>\n",
              "      <td>401698653</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc42ea52-4518-47f6-a7df-b32284565fe1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc42ea52-4518-47f6-a7df-b32284565fe1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc42ea52-4518-47f6-a7df-b32284565fe1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2.set_index('Date', inplace=True)\n"
      ],
      "metadata": {
        "id": "inleJBhA16GH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Store1 =data2[data2['Store']==1].resample('W-MON').sum().drop(['Unnamed: 0', 'Store','Dept','Type','IsHoliday'],axis=1)"
      ],
      "metadata": {
        "id": "9QZryYRQ181Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Store1\n",
        "train = df_Store1.copy()"
      ],
      "metadata": {
        "id": "g0dNcQfp2Als"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standerized the data using Standers Scalar Scaler\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(df_Store1)"
      ],
      "metadata": {
        "id": "maQcoptB2DJL"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "akSX0DOa2GcH",
        "outputId": "fe0cab14-e96c-4aff-c1b0-02534f8242a6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6   \\\n",
              "0    0.305113  0.143964  0.065123  0.000000  0.000000  0.000000  0.000000   \n",
              "1    0.303495  0.064901  0.023625  0.000000  0.000000  0.000000  0.000000   \n",
              "2    0.276300  0.090489  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "3    0.086670  0.211220  0.032658  0.000000  0.000000  0.000000  0.000000   \n",
              "4    0.222125  0.220515  0.102462  0.000000  0.000000  0.000000  0.000000   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "138  0.112189  0.760939  0.835851  0.107505  0.000166  0.000030  0.044367   \n",
              "139  0.330411  0.606211  0.766423  0.233620  0.000000  0.000322  0.111636   \n",
              "140  0.239180  0.521786  0.790058  0.061172  0.000000  0.000145  0.018847   \n",
              "141  0.178488  0.578748  0.715757  0.027103  0.000000  0.000086  0.002442   \n",
              "142  0.165035  0.617203  0.689294  0.074785  0.000681  0.000106  0.032624   \n",
              "\n",
              "           7         8         9    10  \n",
              "0    0.000000  0.479955  1.000000  0.8  \n",
              "1    0.000000  0.363631  0.935181  0.6  \n",
              "2    0.000000  0.365592  0.935181  0.6  \n",
              "3    0.000000  0.366865  0.935181  0.6  \n",
              "4    0.000000  0.490698  1.000000  0.8  \n",
              "..        ...       ...       ...  ...  \n",
              "138  0.231707  0.983083  0.300676  0.8  \n",
              "139  0.174672  0.862121  0.052561  0.6  \n",
              "140  0.289444  1.000000  0.105122  0.8  \n",
              "141  0.109863  0.742756  0.000000  0.4  \n",
              "142  0.062863  0.873092  0.052561  0.6  \n",
              "\n",
              "[143 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-503c90e8-b865-477f-9654-2928e6df5b2a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.305113</td>\n",
              "      <td>0.143964</td>\n",
              "      <td>0.065123</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.479955</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.303495</td>\n",
              "      <td>0.064901</td>\n",
              "      <td>0.023625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.363631</td>\n",
              "      <td>0.935181</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.276300</td>\n",
              "      <td>0.090489</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.365592</td>\n",
              "      <td>0.935181</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.086670</td>\n",
              "      <td>0.211220</td>\n",
              "      <td>0.032658</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366865</td>\n",
              "      <td>0.935181</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.222125</td>\n",
              "      <td>0.220515</td>\n",
              "      <td>0.102462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.490698</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>0.112189</td>\n",
              "      <td>0.760939</td>\n",
              "      <td>0.835851</td>\n",
              "      <td>0.107505</td>\n",
              "      <td>0.000166</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.044367</td>\n",
              "      <td>0.231707</td>\n",
              "      <td>0.983083</td>\n",
              "      <td>0.300676</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>0.330411</td>\n",
              "      <td>0.606211</td>\n",
              "      <td>0.766423</td>\n",
              "      <td>0.233620</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000322</td>\n",
              "      <td>0.111636</td>\n",
              "      <td>0.174672</td>\n",
              "      <td>0.862121</td>\n",
              "      <td>0.052561</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>0.239180</td>\n",
              "      <td>0.521786</td>\n",
              "      <td>0.790058</td>\n",
              "      <td>0.061172</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000145</td>\n",
              "      <td>0.018847</td>\n",
              "      <td>0.289444</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.105122</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>0.178488</td>\n",
              "      <td>0.578748</td>\n",
              "      <td>0.715757</td>\n",
              "      <td>0.027103</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.002442</td>\n",
              "      <td>0.109863</td>\n",
              "      <td>0.742756</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>0.165035</td>\n",
              "      <td>0.617203</td>\n",
              "      <td>0.689294</td>\n",
              "      <td>0.074785</td>\n",
              "      <td>0.000681</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>0.032624</td>\n",
              "      <td>0.062863</td>\n",
              "      <td>0.873092</td>\n",
              "      <td>0.052561</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-503c90e8-b865-477f-9654-2928e6df5b2a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-503c90e8-b865-477f-9654-2928e6df5b2a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-503c90e8-b865-477f-9654-2928e6df5b2a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def autoencoder_model(X):\n",
        "    inputs = Input(shape=(X.shape[1], X.shape[2]))\n",
        "    L1 = LSTM(16, activation='relu', return_sequences=True, \n",
        "              kernel_regularizer=regularizers.l2(0.00))(inputs)\n",
        "    L2 = LSTM(4, activation='relu', return_sequences=False)(L1)\n",
        "    L3 = RepeatVector(X.shape[1])(L2)\n",
        "    L4 = LSTM(4, activation='relu', return_sequences=True)(L3)\n",
        "    L5 = LSTM(16, activation='relu', return_sequences=True)(L4)\n",
        "    output = TimeDistributed(Dense(X.shape[2]))(L5)    \n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "9z6yOtiG2W_L"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape inputs for LSTM [samples, timesteps, features]\n",
        "X_train = X.reshape(X.shape[0], 1, X.shape[1])"
      ],
      "metadata": {
        "id": "_WOu3ryl2bhn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srfNsGw_2hCH",
        "outputId": "bf02008c-0731-43a6-d991-af6cc378aca7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.30511304, 0.14396442, 0.06512319, ..., 0.47995515,\n",
              "         1.        , 0.8       ]],\n",
              "\n",
              "       [[0.30349457, 0.06490074, 0.02362501, ..., 0.3636306 ,\n",
              "         0.93518052, 0.6       ]],\n",
              "\n",
              "       [[0.27630047, 0.09048863, 0.        , ..., 0.36559182,\n",
              "         0.93518052, 0.6       ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.23917958, 0.52178625, 0.79005781, ..., 1.        ,\n",
              "         0.10512175, 0.8       ]],\n",
              "\n",
              "       [[0.17848775, 0.57874834, 0.71575676, ..., 0.74275638,\n",
              "         0.        , 0.4       ]],\n",
              "\n",
              "       [[0.16503458, 0.61720275, 0.68929443, ..., 0.87309211,\n",
              "         0.05256087, 0.6       ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the autoencoder model\n",
        "model = autoencoder_model(X_train)\n",
        "model.compile(optimizer='adam', loss='mae')\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfvyZOaZ2mCR",
        "outputId": "9aaaf9e6-c68c-4917-dc8d-4d8ccbd0140c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.keras.backend.rnn), but are not present in its tracked objects:   <tf.Variable 'lstm/lstm_cell/kernel:0' shape=(11, 64) dtype=float32>\n",
            "  <tf.Variable 'lstm/lstm_cell/recurrent_kernel:0' shape=(16, 64) dtype=float32>\n",
            "  <tf.Variable 'lstm/lstm_cell/bias:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.keras.backend.rnn_1), but are not present in its tracked objects:   <tf.Variable 'lstm_1/lstm_cell_1/kernel:0' shape=(16, 16) dtype=float32>\n",
            "  <tf.Variable 'lstm_1/lstm_cell_1/recurrent_kernel:0' shape=(4, 16) dtype=float32>\n",
            "  <tf.Variable 'lstm_1/lstm_cell_1/bias:0' shape=(16,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.keras.backend.rnn_2), but are not present in its tracked objects:   <tf.Variable 'lstm_2/lstm_cell_2/kernel:0' shape=(4, 16) dtype=float32>\n",
            "  <tf.Variable 'lstm_2/lstm_cell_2/recurrent_kernel:0' shape=(4, 16) dtype=float32>\n",
            "  <tf.Variable 'lstm_2/lstm_cell_2/bias:0' shape=(16,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.keras.backend.rnn_3), but are not present in its tracked objects:   <tf.Variable 'lstm_3/lstm_cell_3/kernel:0' shape=(4, 64) dtype=float32>\n",
            "  <tf.Variable 'lstm_3/lstm_cell_3/recurrent_kernel:0' shape=(16, 64) dtype=float32>\n",
            "  <tf.Variable 'lstm_3/lstm_cell_3/bias:0' shape=(64,) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 1, 11)]      0           []                               \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape (TFOpLambda  (3,)                0           ['input_1[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " tf.zeros (TFOpLambda)          (None, 16)           0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " tf.zeros_1 (TFOpLambda)        (None, 16)           0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " tf.keras.backend.rnn (TFOpLamb  ((None, 16),        0           ['input_1[0][0]',                \n",
            " da)                             (None, 1, 16),                   'tf.zeros[0][0]',               \n",
            "                                 ((None, 16),                     'tf.zeros_1[0][0]']             \n",
            "                                 (None, 16)))                                                     \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_2 (TFOpLamb  (3,)                0           ['tf.keras.backend.rnn[0][1]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  ()                  0           ['tf.compat.v1.shape_2[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.zeros_2 (TFOpLambda)        (None, 4)            0           ['tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.zeros_3 (TFOpLambda)        (None, 4)            0           ['tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.keras.backend.rnn_1 (TFOpLa  ((None, 4),         0           ['tf.keras.backend.rnn[0][1]',   \n",
            " mbda)                           (None, 1, 4),                    'tf.zeros_2[0][0]',             \n",
            "                                 ((None, 4),                      'tf.zeros_3[0][0]']             \n",
            "                                 (None, 4)))                                                      \n",
            "                                                                                                  \n",
            " repeat_vector (RepeatVector)   (None, 1, 4)         0           ['tf.keras.backend.rnn_1[0][0]'] \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_4 (TFOpLamb  (3,)                0           ['repeat_vector[0][0]']          \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4 (Sl  ()                  0           ['tf.compat.v1.shape_4[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.zeros_4 (TFOpLambda)        (None, 4)            0           ['tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.zeros_5 (TFOpLambda)        (None, 4)            0           ['tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.keras.backend.rnn_2 (TFOpLa  ((None, 4),         0           ['repeat_vector[0][0]',          \n",
            " mbda)                           (None, 1, 4),                    'tf.zeros_4[0][0]',             \n",
            "                                 ((None, 4),                      'tf.zeros_5[0][0]']             \n",
            "                                 (None, 4)))                                                      \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_6 (TFOpLamb  (3,)                0           ['tf.keras.backend.rnn_2[0][1]'] \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6 (Sl  ()                  0           ['tf.compat.v1.shape_6[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.zeros_6 (TFOpLambda)        (None, 16)           0           ['tf.__operators__.getitem_6[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.zeros_7 (TFOpLambda)        (None, 16)           0           ['tf.__operators__.getitem_6[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.keras.backend.rnn_3 (TFOpLa  ((None, 16),        0           ['tf.keras.backend.rnn_2[0][1]', \n",
            " mbda)                           (None, 1, 16),                   'tf.zeros_6[0][0]',             \n",
            "                                 ((None, 16),                     'tf.zeros_7[0][0]']             \n",
            "                                 (None, 16)))                                                     \n",
            "                                                                                                  \n",
            " time_distributed (TimeDistribu  (None, 1, 11)       187         ['tf.keras.backend.rnn_3[0][1]'] \n",
            " ted)                                                                                             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 187\n",
            "Trainable params: 187\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model to the data\n",
        "nb_epochs = 100\n",
        "batch_size = 10\n",
        "history = model.fit(X_train, X_train, epochs=nb_epochs, batch_size=batch_size, validation_split=0.05).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o765i7J2pza",
        "outputId": "3ec2809e-2d8a-46e5-c7fb-1cefcf4bf714"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 24s 100ms/step - loss: 0.2798 - val_loss: 0.3336\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2723 - val_loss: 0.3265\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2651 - val_loss: 0.3194\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2581 - val_loss: 0.3123\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2512 - val_loss: 0.3058\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2444 - val_loss: 0.2994\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2380 - val_loss: 0.2932\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2316 - val_loss: 0.2871\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2254 - val_loss: 0.2814\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2196 - val_loss: 0.2761\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.2139 - val_loss: 0.2708\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2084 - val_loss: 0.2656\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.2032 - val_loss: 0.2606\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1981 - val_loss: 0.2559\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1933 - val_loss: 0.2514\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1890 - val_loss: 0.2473\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1850 - val_loss: 0.2435\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1811 - val_loss: 0.2397\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1773 - val_loss: 0.2364\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1739 - val_loss: 0.2333\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1707 - val_loss: 0.2303\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1675 - val_loss: 0.2273\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1645 - val_loss: 0.2246\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1614 - val_loss: 0.2222\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1586 - val_loss: 0.2199\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1560 - val_loss: 0.2175\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1534 - val_loss: 0.2151\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1508 - val_loss: 0.2127\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1483 - val_loss: 0.2104\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1458 - val_loss: 0.2081\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1435 - val_loss: 0.2056\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1412 - val_loss: 0.2033\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1393 - val_loss: 0.2018\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1380 - val_loss: 0.2008\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1368 - val_loss: 0.1998\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1356 - val_loss: 0.1991\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1345 - val_loss: 0.1982\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1335 - val_loss: 0.1976\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1325 - val_loss: 0.1970\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1316 - val_loss: 0.1963\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1306 - val_loss: 0.1959\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1297 - val_loss: 0.1952\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1288 - val_loss: 0.1945\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1281 - val_loss: 0.1938\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1273 - val_loss: 0.1932\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1266 - val_loss: 0.1927\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1259 - val_loss: 0.1923\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1251 - val_loss: 0.1920\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1245 - val_loss: 0.1917\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1239 - val_loss: 0.1914\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1234 - val_loss: 0.1909\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1229 - val_loss: 0.1907\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1224 - val_loss: 0.1905\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1219 - val_loss: 0.1901\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1215 - val_loss: 0.1900\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1211 - val_loss: 0.1899\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1207 - val_loss: 0.1896\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1203 - val_loss: 0.1894\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1200 - val_loss: 0.1889\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1198 - val_loss: 0.1887\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1196 - val_loss: 0.1883\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1194 - val_loss: 0.1881\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 8ms/step - loss: 0.1192 - val_loss: 0.1877\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1191 - val_loss: 0.1876\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1189 - val_loss: 0.1875\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1189 - val_loss: 0.1874\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1188 - val_loss: 0.1869\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1188 - val_loss: 0.1868\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1187 - val_loss: 0.1865\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1187 - val_loss: 0.1864\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1186 - val_loss: 0.1860\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1186 - val_loss: 0.1858\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1185 - val_loss: 0.1855\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1185 - val_loss: 0.1853\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1184 - val_loss: 0.1853\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1184 - val_loss: 0.1849\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.1184 - val_loss: 0.1849\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1183 - val_loss: 0.1848\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1183 - val_loss: 0.1846\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1183 - val_loss: 0.1847\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1183 - val_loss: 0.1845\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1182 - val_loss: 0.1843\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1182 - val_loss: 0.1843\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1182 - val_loss: 0.1842\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1182 - val_loss: 0.1841\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1182 - val_loss: 0.1837\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1182 - val_loss: 0.1837\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1182 - val_loss: 0.1838\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1182 - val_loss: 0.1837\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1182 - val_loss: 0.1837\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1181 - val_loss: 0.1836\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1181 - val_loss: 0.1836\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1181 - val_loss: 0.1832\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1181 - val_loss: 0.1833\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1180 - val_loss: 0.1829\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1180 - val_loss: 0.1829\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1180 - val_loss: 0.1829\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1180 - val_loss: 0.1828\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1180 - val_loss: 0.1827\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 7ms/step - loss: 0.1180 - val_loss: 0.1825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the training losses\n",
        "fig, ax = plt.subplots(figsize=(14, 6), dpi=80)\n",
        "ax.plot(history['loss'], 'b', label='Train', linewidth=2)\n",
        "ax.plot(history['val_loss'], 'r', label='Validation', linewidth=2)\n",
        "ax.set_title('Model loss', fontsize=16)\n",
        "ax.set_ylabel('Loss (MAE)')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "OCCObKN72zVi",
        "outputId": "c05e9c99-39a0-4e29-b7bc-26d0555a6b2a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1120x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss distribution of the training set\n",
        "X_pred = model.predict(X_train)\n",
        "X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\n",
        "X_pred = pd.DataFrame(X_pred, columns=train.columns)\n",
        "X_pred.index = train.index\n",
        "\n",
        "scored = pd.DataFrame(index=train.index)\n",
        "Xtrain = X_train.reshape(X_train.shape[0], X_train.shape[2])\n",
        "scored['Loss_mae'] = np.mean(np.abs(X_pred-Xtrain), axis = 1)\n",
        "plt.figure(figsize=(16,9), dpi=80)\n",
        "plt.title('Loss Distribution', fontsize=16)\n",
        "sns.distplot(scored['Loss_mae'], bins = 20, kde= True, color = 'blue');\n",
        "plt.xlim([0.0,.13])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "2cy5TM3T25cD",
        "outputId": "01cf37d9-167f-4c0b-c000-2d3292762c78"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 0.13)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1280x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pred = model.predict(X_train)\n",
        "X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])\n",
        "X_pred = pd.DataFrame(X_pred, columns=train.columns)\n",
        "X_pred.index = train.index\n",
        "\n",
        "scored = pd.DataFrame(index=train.index)\n",
        "X_train1 = X_train.reshape(X_train.shape[0], X_train.shape[2])\n",
        "scored['Loss_mae'] = np.mean(np.abs(X_pred-X_train1), axis = 1)\n",
        "scored['Threshold'] = 0.11\n",
        "scored['Anomaly'] = scored['Loss_mae'] > scored['Threshold']\n",
        "\n",
        "anomalies = scored[scored.Anomaly == True]\n",
        "anomalies.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "jzEcoKeF2-N5",
        "outputId": "367dc5f3-6877-481e-de13-5dd621d451c6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Loss_mae  Threshold  Anomaly\n",
              "Date                                    \n",
              "2010-02-08  0.144695       0.11     True\n",
              "2010-02-15  0.136469       0.11     True\n",
              "2010-02-22  0.133640       0.11     True\n",
              "2010-03-01  0.124423       0.11     True\n",
              "2010-03-08  0.127798       0.11     True\n",
              "2010-05-24  0.118826       0.11     True\n",
              "2010-05-31  0.125529       0.11     True\n",
              "2010-06-21  0.166180       0.11     True\n",
              "2010-06-28  0.172822       0.11     True\n",
              "2010-07-19  0.137089       0.11     True\n",
              "2010-08-09  0.139661       0.11     True\n",
              "2010-08-30  0.138890       0.11     True\n",
              "2010-12-27  0.141091       0.11     True\n",
              "2011-01-17  0.118287       0.11     True\n",
              "2011-05-16  0.116378       0.11     True\n",
              "2011-07-04  0.114360       0.11     True\n",
              "2011-07-25  0.129297       0.11     True\n",
              "2011-08-01  0.136408       0.11     True\n",
              "2011-08-29  0.167985       0.11     True\n",
              "2011-09-05  0.122797       0.11     True"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7ae45d1-144a-4382-8993-65ffe94e11ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss_mae</th>\n",
              "      <th>Threshold</th>\n",
              "      <th>Anomaly</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2010-02-08</th>\n",
              "      <td>0.144695</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-15</th>\n",
              "      <td>0.136469</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-02-22</th>\n",
              "      <td>0.133640</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-01</th>\n",
              "      <td>0.124423</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-03-08</th>\n",
              "      <td>0.127798</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-05-24</th>\n",
              "      <td>0.118826</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-05-31</th>\n",
              "      <td>0.125529</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-06-21</th>\n",
              "      <td>0.166180</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-06-28</th>\n",
              "      <td>0.172822</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-07-19</th>\n",
              "      <td>0.137089</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-09</th>\n",
              "      <td>0.139661</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-08-30</th>\n",
              "      <td>0.138890</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2010-12-27</th>\n",
              "      <td>0.141091</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-01-17</th>\n",
              "      <td>0.118287</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-05-16</th>\n",
              "      <td>0.116378</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-07-04</th>\n",
              "      <td>0.114360</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-07-25</th>\n",
              "      <td>0.129297</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-08-01</th>\n",
              "      <td>0.136408</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-08-29</th>\n",
              "      <td>0.167985</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2011-09-05</th>\n",
              "      <td>0.122797</td>\n",
              "      <td>0.11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7ae45d1-144a-4382-8993-65ffe94e11ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7ae45d1-144a-4382-8993-65ffe94e11ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7ae45d1-144a-4382-8993-65ffe94e11ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot bearing failure time plot\n",
        "scored.plot(logy=True,  figsize=(16,9), ylim=[1e-3,1e-0], color=['blue','red'])\n",
        "plt.xticks(rotation=90)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "omumRUaT3Bxh",
        "outputId": "84b9a598-2831-4228-ae9d-7701ed8d28bb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2093, 2140, 2192, 2235]), <a list of 4 Text major ticklabel objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vzAuqIjr8TCB"
      },
      "execution_count": 30,
      "outputs": []
    }
  ]
}